{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommender_system_imdb_movies.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAQpYjPVzdsw"
      },
      "source": [
        "# Recommendation Systems on IMDB movie dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dHQTK1zds1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncf3xm1zds2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d233b1ec-8645-48e4-acd8-6437af71ce4d"
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ill6yOzds5"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbQGMevzds8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43f8291-8c96-4b28-c28e-877ba325024b"
      },
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOWqsTGzdtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e0346e-67df-4532-db50-ec7f5616beae"
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0-kPF7zdtE"
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THnkTvjX8Sg1"
      },
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvqWuW5NzdtI"
      },
      "source": [
        "rating_df_train = getData(MOVIELENS_DIR, 'u1.base')\n",
        "rating_df_test = getData(MOVIELENS_DIR, 'u1.test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RPCAd--22MQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "53be00c1-743f-4193-f2b7-515833ac0bc3"
      },
      "source": [
        "rating_df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>874965758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>876893171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>876893119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>889751712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0       1       1       5  874965758\n",
              "1       1       2       3  876893171\n",
              "2       1       3       4  878542960\n",
              "3       1       4       3  876893119\n",
              "4       1       5       3  889751712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj-JamX_4Dai",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f1edd226-822f-4253-e35a-9c7f0ef27531"
      },
      "source": [
        "rating_df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0       1       6       5  887431973\n",
              "1       1      10       3  875693118\n",
              "2       1      12       5  878542960\n",
              "3       1      14       5  874965706\n",
              "4       1      17       3  875073198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpmN2NrTzdtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9839fd72-18b9-4a4c-a6a1-1498a34bf10f"
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users in rating df:\", num_users)\n",
        "print(\"Number of items in rating df:\", num_items)\n",
        "print(\"Number of users in train df:\", len(rating_df_train.userID.unique()))\n",
        "print(\"Number of items in train df:\", len(rating_df_train.itemID.unique()))\n",
        "print(\"Number of users in test df:\", len(rating_df_test.userID.unique()))\n",
        "print(\"Number of items in test df:\", len(rating_df_test.itemID.unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users in rating df: 943\n",
            "Number of items in rating df: 1682\n",
            "Number of users in train df: 943\n",
            "Number of items in train df: 1650\n",
            "Number of users in test df: 459\n",
            "Number of items in test df: 1410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQg7fW9SzdtO"
      },
      "source": [
        "## 1. Data Preprocessing and Baseline algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVaLm25zdtO"
      },
      "source": [
        "### (a) \r\n",
        "Data in recommendation systems is usually encoded as data frame with three or more columns: (user, item, rating, additional meta-data if present). The function dataPreprocessor takes the data frame, total number of users, total number of items and it gives the output a user-item matrix as demonstrated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiG_0QfzdtP"
      },
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "\n",
        "    # Initialize a of size (num_users, numItems) to zeros\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "\n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[userID-1, itemID-1] = rating\n",
        "    \n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6DxbgBmzdtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04a6694-b8e6-4274-a18a-fd0f7102b055"
      },
      "source": [
        "dataPreprocessor(rating_df_train, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4XZHBczdtU"
      },
      "source": [
        "### (b)\r\n",
        "Baseline models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9AkrRvUzdtV"
      },
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "        \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "          # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "          if rating == 0:\n",
        "              # select the row for user\n",
        "              # what's the shape of userVector\n",
        "              userVector = train_matrix[user, :]\n",
        "              \n",
        "              # Extract the items the user already rated\n",
        "              ratedItems = userVector[userVector.nonzero()]\n",
        "              \n",
        "              # If not empty, calculate average and set as rating for the current item\n",
        "              if ratedItems.size == 0:\n",
        "                  itemAvg = 0\n",
        "              else:\n",
        "                  itemAvg = ratedItems.mean()\n",
        "              predictionMatrix[user, item] = itemAvg\n",
        "              \n",
        "          # report progress every 100 users\n",
        "          if (user % 100 == 0 and item == 1):\n",
        "              print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        \n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "    \n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
        "        itemPopularity = np.zeros((num_items))\n",
        "\n",
        "        for item in range(num_items):\n",
        "          numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
        "          numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
        "          if numOfUsersRated == 0:\n",
        "              itemPopularity[item] = 0\n",
        "          else:\n",
        "              itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
        "      \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "          # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "          # if rating == 0:\n",
        "          predictionMatrix[user, item] = itemPopularity[item]\n",
        "              \n",
        "          # report progress every 100 users\n",
        "          if (user % 100 == 0 and item == 1):\n",
        "              print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        self.__model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDw3ALnzdtX"
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJd50FSdzdta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c437522f-489c-48e2-e6e5-0c17136f49df"
      },
      "source": [
        "popularity_recsys.predict_all(rating_df_train, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5TJkUaszdtc"
      },
      "source": [
        "x = popularity_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN8r3Obtzdtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fae257f-ea34-4065-ba31-b73319b521ee"
      },
      "source": [
        "np.all(x<=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZDsDg5Gzdtj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ae24ab4b-3eda-4998-bcbf-452d84d2788d"
      },
      "source": [
        "rating_df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0       1       6       5  887431973\n",
              "1       1      10       3  875693118\n",
              "2       1      12       5  878542960\n",
              "3       1      14       5  874965706\n",
              "4       1      17       3  875073198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p60BEmn-zdtm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "6c8cdfd8-5326-4706-c52d-4bc542421cf0"
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3212.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "      <td>0.698630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "      <td>0.872038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "      <td>0.685714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "      <td>0.472222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  popularity\n",
              "0       1       6       5  887431973    0.500000\n",
              "1       1      10       3  875693118    0.698630\n",
              "2       1      12       5  878542960    0.872038\n",
              "3       1      14       5  874965706    0.685714\n",
              "4       1      17       3  875073198    0.472222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDu_THj3zdtp"
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQWmspQGzdtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6208263a-59bb-495a-e2a7-dd5a37ee78de"
      },
      "source": [
        "average_user_rating_recsys.predict_all(rating_df_train, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl8uLyIqzdty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fad6a4-29f8-480f-ed6e-b71a220cb908"
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 3.68148148, 3.68148148,\n",
              "        3.68148148],\n",
              "       [0.        , 3.8       , 3.8       , ..., 3.8       , 3.8       ,\n",
              "        3.8       ],\n",
              "       [3.        , 3.        , 3.        , ..., 3.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [0.        , 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
              "        4.04545455],\n",
              "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
              "        4.26582278],\n",
              "       [3.41071429, 0.        , 3.41071429, ..., 3.41071429, 3.41071429,\n",
              "        3.41071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSCkkxozdt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "6bbe8114-c03a-46f9-c4d7-689046783bf8"
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3106.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>useraverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "      <td>3.681481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "      <td>3.681481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "      <td>3.681481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "      <td>3.681481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "      <td>3.681481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  useraverage\n",
              "0       1       6       5  887431973     3.681481\n",
              "1       1      10       3  875693118     3.681481\n",
              "2       1      12       5  878542960     3.681481\n",
              "3       1      14       5  874965706     3.681481\n",
              "4       1      17       3  875073198     3.681481"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_RlOlrIzdt7"
      },
      "source": [
        "## 2. Similarity in Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4zY0XYDzdt7"
      },
      "source": [
        "### (a)\r\n",
        "In class SimBasedRecSys, there are two similarity measurement functions (cosine, euclidean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEQ_IkS3zdt8"
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "        similarity_matrix = 1/(1+pairwise_distances(matrix, metric='euclidean'))\n",
        "    \n",
        "        ###########         end         ###########    \n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "  \n",
        "        similarity_matrix = 1/(1+pairwise_distances(matrix, metric='manhattan'))\n",
        "    \n",
        "        ###########         end         ###########        \n",
        "        return similarity_matrix\n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.__model\n",
        "            \n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        \n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "\n",
        "            # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = self.method(train_matrix)\n",
        "            # if k is not None:\n",
        "            #     uu_similarity = kNearestNeighbor(uu_similarity, k)\n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            \n",
        "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "            # predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average  \n",
        "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            self.__model= predictionMatrix \n",
        "\n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "\n",
        "            # Initialize the predicted rating matrix with zeros\n",
        "            train_matrix = train_matrix.transpose()\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = self.method(train_matrix)\n",
        "            # if k is not None:\n",
        "            #     uu_similarity = kNearestNeighbor(uu_similarity, k)\n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(ii_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            \n",
        "            predictionMatrix = np.matmul(ii_similarity, train_matrix)/normalizer\n",
        "            # predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average  \n",
        "            itemaverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "            self.__model= predictionMatrix.T\n",
        "\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "            NOTE: 1. data can have more columns, but your function should ignore \n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine', \n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        self.__model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RROHVWRpzduA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d400b3-11c2-42aa-a35c-c8bc47702e6f"
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3)\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ5BkzGPzduC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d64516f-115e-4eb3-a3eb-1e7d891651d9"
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.41421356, 0.41421356],\n",
              "       [0.41421356, 1.        , 0.41421356],\n",
              "       [0.41421356, 0.41421356, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V-L-T-PzduF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ecb733-64ef-4ca4-d8f4-6d4722fba475"
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAZrJ4pPj-QP"
      },
      "source": [
        "**---- Note ----**\n",
        "\n",
        "Cosine similarity works best here as from the given array of vectors, all are orthogonal to each other, meaning the angle between them is 90 degress. Moreover from a user item perspective, it suggests 3 users who have watched 1 unique movie of the three. So clearly there must not be any similarity in the users and the same is depicted in cosine metric with a 0, **cosine similarity works the best here**. Moreover it is invatiate to scale of dimensions in the vecotor, since it only cares about the angle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USPsbXpnzduH"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtDt6JLrzduI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157095f5-bc79-4981-d610-9aa3aa4c2106"
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PyLzKFgnqjU"
      },
      "source": [
        "**---- Note ----**\n",
        "\n",
        "Using l1 or manhatan distance metric might help here as for high dimensionality, the effects of a few dimension having higher values would be subdued when compared to eucledian where the square of each dimension is taken to calculate the distance.\n",
        "\n",
        "Reference - \n",
        "https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7#:~:text=Manhattan%20distance%20is%20usually%20preferred,similarity%20between%20two%20data%20points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDrJogepzduL"
      },
      "source": [
        "## 3. Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ju9mZE9zduM"
      },
      "source": [
        "### (a)\r\n",
        "Leveraging the user-user collaborative filtering, implement user-user and item-item based collaborative filtering algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAaSIC3BzduM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ce2bf0-c655-4eeb-e062-c61bdb4d2ec3"
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
        "user_cosine_recsys.predict_all(rating_df_train, num_users, num_items)\n",
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.90764656, 3.18309825, 3.00989335, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.85592514, 3.18240388, 2.89077623, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87394327, 3.10905007, 3.02102791, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.92534088, 3.20099215, 3.04206385, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.90921865, 3.21359819, 2.9819897 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.93355541, 3.24681066, 3.05886723, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdxjAZJrzdud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b9649af4-5e39-4b6b-a47e-39695b9e8baf"
      },
      "source": [
        "rating_df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0       1       6       5  887431973\n",
              "1       1      10       3  875693118\n",
              "2       1      12       5  878542960\n",
              "3       1      14       5  874965706\n",
              "4       1      17       3  875073198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2PgKylzdug",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "77e26241-302f-472b-f4b8-9c99136f3a86"
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3120.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "      <td>3.419572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "      <td>3.850140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "      <td>4.400558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "      <td>3.878056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "      <td>3.130335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  user-cosine\n",
              "0       1       6       5  887431973     3.419572\n",
              "1       1      10       3  875693118     3.850140\n",
              "2       1      12       5  878542960     4.400558\n",
              "3       1      14       5  874965706     3.878056\n",
              "4       1      17       3  875073198     3.130335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ic_FKWUzdui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6974d79c-e0d0-412a-b173-562edb6c0324"
      },
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
        "item_cosine_recsys.predict_all(rating_df_train, num_users, num_items)\n",
        "item_cosine_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.85156994, 3.7342213 , 3.83843022, ..., 4.11798149, 3.90551101,\n",
              "        3.9598337 ],\n",
              "       [3.87401875, 3.85300753, 3.82228493, ..., 3.77601163, 3.95744705,\n",
              "        4.09365253],\n",
              "       [2.96947266, 3.03381501, 2.94253433, ..., 3.12417711, 3.27065656,\n",
              "        2.79578581],\n",
              "       ...,\n",
              "       [4.11724041, 4.06618477, 4.0274836 , ..., 4.        , 3.88126854,\n",
              "        4.14874911],\n",
              "       [4.37234448, 4.42355222, 4.34195687, ..., 3.95265019, 4.41470077,\n",
              "        4.57717283],\n",
              "       [3.52291931, 3.4890315 , 3.53459055, ..., 0.        , 3.608216  ,\n",
              "        3.59916709]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fao5_zUBJvjV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "1c8d6270-36c3-41ee-f3aa-045338d78178"
      },
      "source": [
        "item_cosine_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3016.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>item-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "      <td>4.047083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "      <td>3.976599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "      <td>3.889206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "      <td>4.024444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "      <td>3.779897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  item-cosine\n",
              "0       1       6       5  887431973     4.047083\n",
              "1       1      10       3  875693118     3.976599\n",
              "2       1      12       5  878542960     3.889206\n",
              "3       1      14       5  874965706     4.024444\n",
              "4       1      17       3  875073198     3.779897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9aOwAS4J3vG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZdTvp_szduk"
      },
      "source": [
        "### (b)\r\n",
        "class CrossValidation to report comparative RMSE results (averages and  confidence intervals) between user-user and item-item based collaborative  filtering for cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BnXbsLzdul"
      },
      "source": [
        "dclass CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "            'RPrecision': self.rprecision\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "\n",
        "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet = self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRPs = 0\n",
        "        countRPs = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID, :]\n",
        "\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID, :]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take)\n",
        "            # Calculate recall\n",
        "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRPs += rp\n",
        "            countRPs += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRPs) / countRPs\n",
        "\n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKyb9l-zdun"
      },
      "source": [
        "# How to use CrossValidation Class?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU3rZPtnzdus"
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [item_cosine_recsys, user_cosine_recsys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-m7d5Dzdux"
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, RPrecision\n",
        "# Precision at K in this example\n",
        "cv_patk = CrossValidation('RMSE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqcihyZdzduz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e11966e-f528-452b-81b4-08570a4e4215"
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3050.22it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3076.82it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3085.78it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3094.45it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 2964.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2875.90it/s]\n",
            "20000it [00:06, 3076.40it/s]\n",
            "20000it [00:06, 3110.37it/s]\n",
            "20000it [00:06, 3067.35it/s]\n",
            "20000it [00:06, 3021.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[1.0377631264364244,\n",
              "   1.0207280585350078,\n",
              "   1.0101820660011798,\n",
              "   1.0136832839209695,\n",
              "   1.0180579656376574],\n",
              "  1.020082900106248,\n",
              "  1.0068242686250732,\n",
              "  1.0333415315874226],\n",
              " 'user-cosine': [[1.026449013124381,\n",
              "   1.0214387664779507,\n",
              "   1.0132940326457187,\n",
              "   1.0094003999022947,\n",
              "   1.0161883961525586],\n",
              "  1.0173541216605808,\n",
              "  1.009013080226148,\n",
              "  1.0256951630950135]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1aJB_q7zZLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9181eb3-7c4e-42c1-ec4f-69924159f98b"
      },
      "source": [
        "avg_ratings_per_user = rating_df.groupby('userID').size().to_frame(name='len_ratings')['len_ratings'].mean()\n",
        "avg_ratings_per_item = rating_df.groupby('itemID').size().to_frame(name='len_ratings')['len_ratings'].mean()\n",
        "\n",
        "print ('avg. number of ratings per user =', avg_ratings_per_user)\n",
        "print ('\\navg number of ratings per item =', avg_ratings_per_item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg. number of ratings per user = 106.04453870625663\n",
            "\n",
            "avg number of ratings per item = 59.45303210463734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJso9Wu_3mDV"
      },
      "source": [
        "**---- Note ----**\n",
        "\n",
        "User-cosine RMSE = 1.0173 CI = 1.0090, 1.0256\n",
        "\n",
        "Item-cosine RMSE = 1.0200 CI = 1.0068, 1.0333\n",
        "\n",
        "\n",
        "**User based cosine similarity collaborative filtering performed better** (lower RMSE and smaller range of confidence interval) as the number of datapoints available per user were more to take a better informed decision about the missing data points. (avg number of ratings per user = 106.04 and avg number of ratings per item = 59.45)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCFpLY25JuY"
      },
      "source": [
        "## 4. Probabilistic Matrix Factorization(PMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMdW5aLG5OTH"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1hS4CP5RVP"
      },
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "            \n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "            \n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "                \n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ########### your code goes here ###########\n",
        "    \n",
        "        self.w_Item = sqrt(0.1)*np.random.randn(num_item, self.num_feat)  # item M x D \n",
        "        self.w_User = sqrt(0.1)*np.random.randn(num_user, self.num_feat)  # user N x D \n",
        "    \n",
        "        ###########         end         ###########\n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########\n",
        "            \n",
        "                pred_out = np.sum(self.w_Item[batch_ItemID]*self.w_User[batch_UserID], axis=1) #size (batch_size, )\n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(self.w_Item[train_item_idx]*self.w_User[train_user_idx], axis=1) # size(pairs_train, )\n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(self.w_Item[val_item_idx]*self.w_User[val_user_idx], axis=1) #size(pairs_val, )\n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None \n",
        "            self.w_User = None \n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)\n",
        "        else:\n",
        "          raise Exception(\"You need to pass in a dictionary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce7wlxycY76k"
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 17, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':False})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p56cFny7Y_Z_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cee50d65-d5bb-4237-efb8-3a6a3d7d304b"
      },
      "source": [
        "pmf.predict_all(rating_df, num_users, num_items)\n",
        "pmf.plot_error()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkSLeDqzdu1"
      },
      "source": [
        "## 5. Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00OSiRl9zdu2"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpApK2Taddy1"
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [popularity_recsys,\n",
        "                       average_user_rating_recsys,\n",
        "                       user_cosine_recsys,\n",
        "                       item_cosine_recsys,\n",
        "                       pmf]\n",
        "\n",
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, RPrecision\n",
        "# Precision at K in this example\n",
        "cv_rmse = CrossValidation('RMSE')\n",
        "cv_patk = CrossValidation('P@K')\n",
        "cv_rprec = CrossValidation('RPrecision')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-c07qJYddy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc527aa-c77c-4415-a9f3-1c63a472cb32"
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "\n",
        "rmse_results = cv_rmse.run(algorithm_instances, num_users, num_items,k=5)\n",
        "patk_results = cv_patk.run(algorithm_instances, num_users, num_items,k=5)\n",
        "rprec_results = cv_rprec.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2846.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3084.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3125.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3084.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3070.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3075.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3123.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3134.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3073.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3139.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3040.66it/s]\n",
            "20000it [00:06, 3108.01it/s]\n",
            "20000it [00:06, 3111.58it/s]\n",
            "20000it [00:06, 3093.72it/s]\n",
            "20000it [00:06, 3052.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3035.15it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3065.13it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3118.57it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3084.75it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3076.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:11, 1699.08it/s]\n",
            "20000it [00:11, 1682.56it/s]\n",
            "20000it [00:11, 1697.56it/s]\n",
            "20000it [00:11, 1677.03it/s]\n",
            "20000it [00:11, 1695.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3083.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3047.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3074.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3074.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3115.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3105.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3079.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3133.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3164.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3085.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2975.92it/s]\n",
            "20000it [00:06, 3098.45it/s]\n",
            "20000it [00:06, 3200.30it/s]\n",
            "20000it [00:06, 3169.51it/s]\n",
            "20000it [00:06, 3130.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3093.20it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3062.65it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3089.90it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3065.65it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3018.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:11, 1666.77it/s]\n",
            "20000it [00:11, 1668.42it/s]\n",
            "20000it [00:11, 1692.83it/s]\n",
            "20000it [00:11, 1686.24it/s]\n",
            "20000it [00:11, 1700.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3081.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2980.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3029.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3078.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3105.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3079.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3085.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3102.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3138.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3136.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 3104.52it/s]\n",
            "20000it [00:06, 3100.18it/s]\n",
            "20000it [00:06, 3032.63it/s]\n",
            "20000it [00:06, 3095.11it/s]\n",
            "20000it [00:06, 3069.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3105.04it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3074.75it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3097.36it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3093.15it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:06, 3103.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:11, 1706.25it/s]\n",
            "20000it [00:11, 1719.24it/s]\n",
            "20000it [00:11, 1730.69it/s]\n",
            "20000it [00:11, 1715.19it/s]\n",
            "20000it [00:11, 1703.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dloUtJE2h5aR"
      },
      "source": [
        "rmse_results_df = pd.DataFrame(rmse_results, index=['each_fold_rmse', 'mean_rmse', 'min', 'max'])\n",
        "patk_results_df = pd.DataFrame(patk_results, index=['each_fold_patk', 'mean_patk', 'min', 'max'])\n",
        "rprec_results_df = pd.DataFrame(rprec_results, index=['each_fold_rprec', 'mean_rprec', 'min', 'max'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQr63qsuh8Un",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "324c20bc-e93c-467f-ac00-30c46c3ad1b5"
      },
      "source": [
        "rmse_results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>useraverage</th>\n",
              "      <th>user-cosine</th>\n",
              "      <th>item-cosine</th>\n",
              "      <th>PMF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>each_fold_rmse</th>\n",
              "      <td>[3.177941281084362, 3.1750480150769977, 3.1474...</td>\n",
              "      <td>[1.0629951276561334, 1.0467467492319966, 1.032...</td>\n",
              "      <td>[1.026449013124381, 1.0214387664779507, 1.0132...</td>\n",
              "      <td>[1.0377631264364244, 1.0207280585350078, 1.010...</td>\n",
              "      <td>[0.9851786271606422, 0.9686605530968466, 0.961...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_rmse</th>\n",
              "      <td>3.15909</td>\n",
              "      <td>1.04372</td>\n",
              "      <td>1.01735</td>\n",
              "      <td>1.02008</td>\n",
              "      <td>0.967591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.13929</td>\n",
              "      <td>1.02893</td>\n",
              "      <td>1.00901</td>\n",
              "      <td>1.00682</td>\n",
              "      <td>0.953404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.17889</td>\n",
              "      <td>1.0585</td>\n",
              "      <td>1.0257</td>\n",
              "      <td>1.03334</td>\n",
              "      <td>0.981777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       popularity  ...                                                PMF\n",
              "each_fold_rmse  [3.177941281084362, 3.1750480150769977, 3.1474...  ...  [0.9851786271606422, 0.9686605530968466, 0.961...\n",
              "mean_rmse                                                 3.15909  ...                                           0.967591\n",
              "min                                                       3.13929  ...                                           0.953404\n",
              "max                                                       3.17889  ...                                           0.981777\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDvDERTuiCXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "3bf4867b-8680-4a94-a643-2616f24b9e2d"
      },
      "source": [
        "patk_results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>useraverage</th>\n",
              "      <th>user-cosine</th>\n",
              "      <th>item-cosine</th>\n",
              "      <th>PMF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>each_fold_patk</th>\n",
              "      <td>[0.36924708377518656, 0.4965005302226948, 0.61...</td>\n",
              "      <td>[0.30604453870625714, 0.4305408271474029, 0.53...</td>\n",
              "      <td>[0.37179215270413657, 0.503923647932133, 0.621...</td>\n",
              "      <td>[0.34316012725344736, 0.483563096500532, 0.602...</td>\n",
              "      <td>[0.36139978791092325, 0.492895015906682, 0.615...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_patk</th>\n",
              "      <td>0.550583</td>\n",
              "      <td>0.473637</td>\n",
              "      <td>0.555843</td>\n",
              "      <td>0.532216</td>\n",
              "      <td>0.545366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.405441</td>\n",
              "      <td>0.341999</td>\n",
              "      <td>0.409598</td>\n",
              "      <td>0.383701</td>\n",
              "      <td>0.39918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.695725</td>\n",
              "      <td>0.605275</td>\n",
              "      <td>0.702088</td>\n",
              "      <td>0.680732</td>\n",
              "      <td>0.691552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       popularity  ...                                                PMF\n",
              "each_fold_patk  [0.36924708377518656, 0.4965005302226948, 0.61...  ...  [0.36139978791092325, 0.492895015906682, 0.615...\n",
              "mean_patk                                                0.550583  ...                                           0.545366\n",
              "min                                                      0.405441  ...                                            0.39918\n",
              "max                                                      0.695725  ...                                           0.691552\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvpdhlCkiCP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "5baf06eb-84d8-454b-ebd5-c73bbc3fe4dd"
      },
      "source": [
        "rprec_results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>useraverage</th>\n",
              "      <th>user-cosine</th>\n",
              "      <th>item-cosine</th>\n",
              "      <th>PMF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>each_fold_rprec</th>\n",
              "      <td>[0.7177873723889607, 0.7070154178036713, 0.712...</td>\n",
              "      <td>[0.6403680886295169, 0.6452698039088018, 0.641...</td>\n",
              "      <td>[0.7177834541075783, 0.7127674206396806, 0.715...</td>\n",
              "      <td>[0.6999034077107555, 0.7051212779090774, 0.713...</td>\n",
              "      <td>[0.6969074468574826, 0.6876902522222452, 0.699...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_rprec</th>\n",
              "      <td>0.717666</td>\n",
              "      <td>0.64573</td>\n",
              "      <td>0.721019</td>\n",
              "      <td>0.708014</td>\n",
              "      <td>0.70088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.706824</td>\n",
              "      <td>0.639631</td>\n",
              "      <td>0.709995</td>\n",
              "      <td>0.700692</td>\n",
              "      <td>0.688275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.728509</td>\n",
              "      <td>0.65183</td>\n",
              "      <td>0.732042</td>\n",
              "      <td>0.715336</td>\n",
              "      <td>0.713484</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        popularity  ...                                                PMF\n",
              "each_fold_rprec  [0.7177873723889607, 0.7070154178036713, 0.712...  ...  [0.6969074468574826, 0.6876902522222452, 0.699...\n",
              "mean_rprec                                                0.717666  ...                                            0.70088\n",
              "min                                                       0.706824  ...                                           0.688275\n",
              "max                                                       0.728509  ...                                           0.713484\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ndWFEgUzdu4"
      },
      "source": [
        "### (b)\n",
        "\n",
        "**---- Note ----**\n",
        "\n",
        "1. Popularity baseline cannot be evaluated with RMSE as the predictions of popularity based rec sys is in 0 and 1 while the comparison is between 0-5, hence it would always yield a high RMSE.\n",
        "\n",
        "2. Useraverage baseline cannot be evaluated with p@k and rprec as the useraverage would give the same user average output for all the unrated items hence rendering the ranked evaluation of p@k and rprec useless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zcw5EhLv3_vw"
      },
      "source": [
        "### (c)\n",
        "\n",
        "**---- Note ----**\n",
        "1. RMSE = PMF (0.96) is the best as gradient descent is used to minimise the prediction errors\n",
        "2. P@k = user-cosine (0.55) is the best as it uses the data from the similar users who have rated the item\n",
        "3. Rprec = user-cosine (0.72) is the best as it uses the data from the similar users who have rated the item "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCRXRKJd5hs0"
      },
      "source": [
        "### (d)\n",
        "\n",
        "**---- Note ----**\n",
        "\n",
        "No, high rmse does not imply good performance at p@k or rprec as rmse treats all the retreived recommendations equally while r@p and rprec consider the ranking of the relevant recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkx8GW4wzdu8"
      },
      "source": [
        "## 6. Similarity Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnLcDctYzdu9"
      },
      "source": [
        "### (a)\r\n",
        "Go through the list of movies and pick three not-so-popular movies that you know well. I.e., do not choose \\Star Wars\" and note that we expect everyone in the class to have chosen different movies. For each of these three movies, list the top 5 most similar movie names according to item-item cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16agjyHzdu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae46f8d8-0a65-431f-88d2-935606ce8bb3"
      },
      "source": [
        "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
        "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
        "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
        "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
        "\n",
        "for i in moviesDF.movieTitle.unique():\n",
        "  print (i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Toy Story (1995)\n",
            "GoldenEye (1995)\n",
            "Four Rooms (1995)\n",
            "Get Shorty (1995)\n",
            "Copycat (1995)\n",
            "Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)\n",
            "Twelve Monkeys (1995)\n",
            "Babe (1995)\n",
            "Dead Man Walking (1995)\n",
            "Richard III (1995)\n",
            "Seven (Se7en) (1995)\n",
            "Usual Suspects, The (1995)\n",
            "Mighty Aphrodite (1995)\n",
            "Postino, Il (1994)\n",
            "Mr. Holland's Opus (1995)\n",
            "French Twist (Gazon maudit) (1995)\n",
            "From Dusk Till Dawn (1996)\n",
            "White Balloon, The (1995)\n",
            "Antonia's Line (1995)\n",
            "Angels and Insects (1995)\n",
            "Muppet Treasure Island (1996)\n",
            "Braveheart (1995)\n",
            "Taxi Driver (1976)\n",
            "Rumble in the Bronx (1995)\n",
            "Birdcage, The (1996)\n",
            "Brothers McMullen, The (1995)\n",
            "Bad Boys (1995)\n",
            "Apollo 13 (1995)\n",
            "Batman Forever (1995)\n",
            "Belle de jour (1967)\n",
            "Crimson Tide (1995)\n",
            "Crumb (1994)\n",
            "Desperado (1995)\n",
            "Doom Generation, The (1995)\n",
            "Free Willy 2: The Adventure Home (1995)\n",
            "Mad Love (1995)\n",
            "Nadja (1994)\n",
            "Net, The (1995)\n",
            "Strange Days (1995)\n",
            "To Wong Foo, Thanks for Everything! Julie Newmar (1995)\n",
            "Billy Madison (1995)\n",
            "Clerks (1994)\n",
            "Disclosure (1994)\n",
            "Dolores Claiborne (1994)\n",
            "Eat Drink Man Woman (1994)\n",
            "Exotica (1994)\n",
            "Ed Wood (1994)\n",
            "Hoop Dreams (1994)\n",
            "I.Q. (1994)\n",
            "Star Wars (1977)\n",
            "Legends of the Fall (1994)\n",
            "Madness of King George, The (1994)\n",
            "Natural Born Killers (1994)\n",
            "Outbreak (1995)\n",
            "Professional, The (1994)\n",
            "Pulp Fiction (1994)\n",
            "Priest (1994)\n",
            "Quiz Show (1994)\n",
            "Three Colors: Red (1994)\n",
            "Three Colors: Blue (1993)\n",
            "Three Colors: White (1994)\n",
            "Stargate (1994)\n",
            "Santa Clause, The (1994)\n",
            "Shawshank Redemption, The (1994)\n",
            "What's Eating Gilbert Grape (1993)\n",
            "While You Were Sleeping (1995)\n",
            "Ace Ventura: Pet Detective (1994)\n",
            "Crow, The (1994)\n",
            "Forrest Gump (1994)\n",
            "Four Weddings and a Funeral (1994)\n",
            "Lion King, The (1994)\n",
            "Mask, The (1994)\n",
            "Maverick (1994)\n",
            "Faster Pussycat! Kill! Kill! (1965)\n",
            "Brother Minister: The Assassination of Malcolm X (1994)\n",
            "Carlito's Way (1993)\n",
            "Firm, The (1993)\n",
            "Free Willy (1993)\n",
            "Fugitive, The (1993)\n",
            "Hot Shots! Part Deux (1993)\n",
            "Hudsucker Proxy, The (1994)\n",
            "Jurassic Park (1993)\n",
            "Much Ado About Nothing (1993)\n",
            "Robert A. Heinlein's The Puppet Masters (1994)\n",
            "Ref, The (1994)\n",
            "Remains of the Day, The (1993)\n",
            "Searching for Bobby Fischer (1993)\n",
            "Sleepless in Seattle (1993)\n",
            "Blade Runner (1982)\n",
            "So I Married an Axe Murderer (1993)\n",
            "Nightmare Before Christmas, The (1993)\n",
            "True Romance (1993)\n",
            "Welcome to the Dollhouse (1995)\n",
            "Home Alone (1990)\n",
            "Aladdin (1992)\n",
            "Terminator 2: Judgment Day (1991)\n",
            "Dances with Wolves (1990)\n",
            "Silence of the Lambs, The (1991)\n",
            "Snow White and the Seven Dwarfs (1937)\n",
            "Fargo (1996)\n",
            "Heavy Metal (1981)\n",
            "Aristocats, The (1970)\n",
            "All Dogs Go to Heaven 2 (1996)\n",
            "Theodore Rex (1995)\n",
            "Sgt. Bilko (1996)\n",
            "Diabolique (1996)\n",
            "Moll Flanders (1996)\n",
            "Kids in the Hall: Brain Candy (1996)\n",
            "Mystery Science Theater 3000: The Movie (1996)\n",
            "Operation Dumbo Drop (1995)\n",
            "Truth About Cats & Dogs, The (1996)\n",
            "Flipper (1996)\n",
            "Horseman on the Roof, The (Hussard sur le toit, Le) (1995)\n",
            "Wallace & Gromit: The Best of Aardman Animation (1996)\n",
            "Haunted World of Edward D. Wood Jr., The (1995)\n",
            "Cold Comfort Farm (1995)\n",
            "Rock, The (1996)\n",
            "Twister (1996)\n",
            "Maya Lin: A Strong Clear Vision (1994)\n",
            "Striptease (1996)\n",
            "Independence Day (ID4) (1996)\n",
            "Cable Guy, The (1996)\n",
            "Frighteners, The (1996)\n",
            "Lone Star (1996)\n",
            "Phenomenon (1996)\n",
            "Spitfire Grill, The (1996)\n",
            "Godfather, The (1972)\n",
            "Supercop (1992)\n",
            "Bound (1996)\n",
            "Kansas City (1996)\n",
            "Breakfast at Tiffany's (1961)\n",
            "Wizard of Oz, The (1939)\n",
            "Gone with the Wind (1939)\n",
            "Citizen Kane (1941)\n",
            "2001: A Space Odyssey (1968)\n",
            "Mr. Smith Goes to Washington (1939)\n",
            "Big Night (1996)\n",
            "D3: The Mighty Ducks (1996)\n",
            "Love Bug, The (1969)\n",
            "Homeward Bound: The Incredible Journey (1993)\n",
            "20,000 Leagues Under the Sea (1954)\n",
            "Bedknobs and Broomsticks (1971)\n",
            "Sound of Music, The (1965)\n",
            "Die Hard (1988)\n",
            "Lawnmower Man, The (1992)\n",
            "Unhook the Stars (1996)\n",
            "Long Kiss Goodnight, The (1996)\n",
            "Ghost and the Darkness, The (1996)\n",
            "Jude (1996)\n",
            "Swingers (1996)\n",
            "Willy Wonka and the Chocolate Factory (1971)\n",
            "Sleeper (1973)\n",
            "Fish Called Wanda, A (1988)\n",
            "Monty Python's Life of Brian (1979)\n",
            "Dirty Dancing (1987)\n",
            "Reservoir Dogs (1992)\n",
            "Platoon (1986)\n",
            "Weekend at Bernie's (1989)\n",
            "Basic Instinct (1992)\n",
            "Glengarry Glen Ross (1992)\n",
            "Top Gun (1986)\n",
            "On Golden Pond (1981)\n",
            "Return of the Pink Panther, The (1974)\n",
            "Abyss, The (1989)\n",
            "Jean de Florette (1986)\n",
            "Manon of the Spring (Manon des sources) (1986)\n",
            "Private Benjamin (1980)\n",
            "Monty Python and the Holy Grail (1974)\n",
            "Wrong Trousers, The (1993)\n",
            "Cinema Paradiso (1988)\n",
            "Delicatessen (1991)\n",
            "Empire Strikes Back, The (1980)\n",
            "Princess Bride, The (1987)\n",
            "Raiders of the Lost Ark (1981)\n",
            "Brazil (1985)\n",
            "Aliens (1986)\n",
            "Good, The Bad and The Ugly, The (1966)\n",
            "12 Angry Men (1957)\n",
            "Clockwork Orange, A (1971)\n",
            "Apocalypse Now (1979)\n",
            "Return of the Jedi (1983)\n",
            "GoodFellas (1990)\n",
            "Alien (1979)\n",
            "Army of Darkness (1993)\n",
            "Psycho (1960)\n",
            "Blues Brothers, The (1980)\n",
            "Godfather: Part II, The (1974)\n",
            "Full Metal Jacket (1987)\n",
            "Grand Day Out, A (1992)\n",
            "Henry V (1989)\n",
            "Amadeus (1984)\n",
            "Raging Bull (1980)\n",
            "Right Stuff, The (1983)\n",
            "Sting, The (1973)\n",
            "Terminator, The (1984)\n",
            "Dead Poets Society (1989)\n",
            "Graduate, The (1967)\n",
            "Nikita (La Femme Nikita) (1990)\n",
            "Bridge on the River Kwai, The (1957)\n",
            "Shining, The (1980)\n",
            "Evil Dead II (1987)\n",
            "Groundhog Day (1993)\n",
            "Unforgiven (1992)\n",
            "Back to the Future (1985)\n",
            "Patton (1970)\n",
            "Akira (1988)\n",
            "Cyrano de Bergerac (1990)\n",
            "Young Frankenstein (1974)\n",
            "This Is Spinal Tap (1984)\n",
            "Indiana Jones and the Last Crusade (1989)\n",
            "M*A*S*H (1970)\n",
            "Unbearable Lightness of Being, The (1988)\n",
            "Room with a View, A (1986)\n",
            "Pink Floyd - The Wall (1982)\n",
            "Field of Dreams (1989)\n",
            "When Harry Met Sally... (1989)\n",
            "Bram Stoker's Dracula (1992)\n",
            "Cape Fear (1991)\n",
            "Nightmare on Elm Street, A (1984)\n",
            "Mirror Has Two Faces, The (1996)\n",
            "Breaking the Waves (1996)\n",
            "Star Trek: First Contact (1996)\n",
            "Sling Blade (1996)\n",
            "Ridicule (1996)\n",
            "101 Dalmatians (1996)\n",
            "Die Hard 2 (1990)\n",
            "Star Trek VI: The Undiscovered Country (1991)\n",
            "Star Trek: The Wrath of Khan (1982)\n",
            "Star Trek III: The Search for Spock (1984)\n",
            "Star Trek IV: The Voyage Home (1986)\n",
            "Batman Returns (1992)\n",
            "Young Guns (1988)\n",
            "Under Siege (1992)\n",
            "Jaws (1975)\n",
            "Mars Attacks! (1996)\n",
            "Citizen Ruth (1996)\n",
            "Jerry Maguire (1996)\n",
            "Raising Arizona (1987)\n",
            "Sneakers (1992)\n",
            "Beavis and Butt-head Do America (1996)\n",
            "Last of the Mohicans, The (1992)\n",
            "Kolya (1996)\n",
            "Jungle2Jungle (1997)\n",
            "Smilla's Sense of Snow (1997)\n",
            "Devil's Own, The (1997)\n",
            "Chasing Amy (1997)\n",
            "Turbo: A Power Rangers Movie (1997)\n",
            "Grosse Pointe Blank (1997)\n",
            "Austin Powers: International Man of Mystery (1997)\n",
            "Fifth Element, The (1997)\n",
            "Shall We Dance? (1996)\n",
            "Lost World: Jurassic Park, The (1997)\n",
            "Pillow Book, The (1995)\n",
            "Batman & Robin (1997)\n",
            "My Best Friend's Wedding (1997)\n",
            "When the Cats Away (Chacun cherche son chat) (1996)\n",
            "Men in Black (1997)\n",
            "Contact (1997)\n",
            "George of the Jungle (1997)\n",
            "Event Horizon (1997)\n",
            "Air Bud (1997)\n",
            "In the Company of Men (1997)\n",
            "Steel (1997)\n",
            "Mimic (1997)\n",
            "Hunt for Red October, The (1990)\n",
            "Kull the Conqueror (1997)\n",
            "unknown\n",
            "Full Monty, The (1997)\n",
            "Gattaca (1997)\n",
            "Starship Troopers (1997)\n",
            "Good Will Hunting (1997)\n",
            "Heat (1995)\n",
            "Sabrina (1995)\n",
            "Sense and Sensibility (1995)\n",
            "Leaving Las Vegas (1995)\n",
            "Restoration (1995)\n",
            "Bed of Roses (1996)\n",
            "Once Upon a Time... When We Were Colored (1995)\n",
            "Up Close and Personal (1996)\n",
            "River Wild, The (1994)\n",
            "Time to Kill, A (1996)\n",
            "Emma (1996)\n",
            "Tin Cup (1996)\n",
            "Secrets & Lies (1996)\n",
            "English Patient, The (1996)\n",
            "Marvin's Room (1996)\n",
            "Scream (1996)\n",
            "Evita (1996)\n",
            "Fierce Creatures (1997)\n",
            "Absolute Power (1997)\n",
            "Rosewood (1997)\n",
            "Donnie Brasco (1997)\n",
            "Liar Liar (1997)\n",
            "Breakdown (1997)\n",
            "Promesse, La (1996)\n",
            "Ulee's Gold (1997)\n",
            "Face/Off (1997)\n",
            "Hoodlum (1997)\n",
            "Air Force One (1997)\n",
            "In & Out (1997)\n",
            "L.A. Confidential (1997)\n",
            "Fly Away Home (1996)\n",
            "Ice Storm, The (1997)\n",
            "Mrs. Brown (Her Majesty, Mrs. Brown) (1997)\n",
            "Devil's Advocate, The (1997)\n",
            "FairyTale: A True Story (1997)\n",
            "Deceiver (1997)\n",
            "Rainmaker, The (1997)\n",
            "Wings of the Dove, The (1997)\n",
            "Midnight in the Garden of Good and Evil (1997)\n",
            "Titanic (1997)\n",
            "3 Ninjas: High Noon At Mega Mountain (1998)\n",
            "Apt Pupil (1998)\n",
            "As Good As It Gets (1997)\n",
            "In the Name of the Father (1993)\n",
            "Schindler's List (1993)\n",
            "Everyone Says I Love You (1996)\n",
            "Paradise Lost: The Child Murders at Robin Hood Hills (1996)\n",
            "Mother (1996)\n",
            "Murder at 1600 (1997)\n",
            "Dante's Peak (1997)\n",
            "Lost Highway (1997)\n",
            "Crash (1996)\n",
            "G.I. Jane (1997)\n",
            "Cop Land (1997)\n",
            "Conspiracy Theory (1997)\n",
            "Desperate Measures (1998)\n",
            "187 (1997)\n",
            "Edge, The (1997)\n",
            "Kiss the Girls (1997)\n",
            "Game, The (1997)\n",
            "U Turn (1997)\n",
            "How to Be a Player (1997)\n",
            "Playing God (1997)\n",
            "House of Yes, The (1997)\n",
            "Bean (1997)\n",
            "Mad City (1997)\n",
            "Boogie Nights (1997)\n",
            "Critical Care (1997)\n",
            "Man Who Knew Too Little, The (1997)\n",
            "Alien: Resurrection (1997)\n",
            "Apostle, The (1997)\n",
            "Deconstructing Harry (1997)\n",
            "Jackie Brown (1997)\n",
            "Wag the Dog (1997)\n",
            "Hard Rain (1998)\n",
            "Fallen (1998)\n",
            "Prophecy II, The (1998)\n",
            "Spice World (1997)\n",
            "Deep Rising (1998)\n",
            "Wedding Singer, The (1998)\n",
            "Sphere (1998)\n",
            "Client, The (1994)\n",
            "One Flew Over the Cuckoo's Nest (1975)\n",
            "Spawn (1997)\n",
            "Assignment, The (1997)\n",
            "Wonderland (1997)\n",
            "Incognito (1997)\n",
            "Blues Brothers 2000 (1998)\n",
            "Sudden Death (1995)\n",
            "Ace Ventura: When Nature Calls (1995)\n",
            "Powder (1995)\n",
            "Dangerous Minds (1995)\n",
            "Clueless (1995)\n",
            "Bio-Dome (1996)\n",
            "Black Sheep (1996)\n",
            "Mary Reilly (1996)\n",
            "Bridges of Madison County, The (1995)\n",
            "Jeffrey (1995)\n",
            "Judge Dredd (1995)\n",
            "Mighty Morphin Power Rangers: The Movie (1995)\n",
            "Showgirls (1995)\n",
            "Houseguest (1994)\n",
            "Heavyweights (1994)\n",
            "Miracle on 34th Street (1994)\n",
            "Tales From the Crypt Presents: Demon Knight (1995)\n",
            "Star Trek: Generations (1994)\n",
            "Muriel's Wedding (1994)\n",
            "Adventures of Priscilla, Queen of the Desert, The (1994)\n",
            "Flintstones, The (1994)\n",
            "Naked Gun 33 1/3: The Final Insult (1994)\n",
            "True Lies (1994)\n",
            "Addams Family Values (1993)\n",
            "Age of Innocence, The (1993)\n",
            "Beverly Hills Cop III (1994)\n",
            "Black Beauty (1994)\n",
            "Fear of a Black Hat (1993)\n",
            "Last Action Hero (1993)\n",
            "Man Without a Face, The (1993)\n",
            "Mrs. Doubtfire (1993)\n",
            "Radioland Murders (1994)\n",
            "Robin Hood: Men in Tights (1993)\n",
            "Serial Mom (1994)\n",
            "Striking Distance (1993)\n",
            "Super Mario Bros. (1993)\n",
            "Three Musketeers, The (1993)\n",
            "Little Rascals, The (1994)\n",
            "Brady Bunch Movie, The (1995)\n",
            "Ghost (1990)\n",
            "Batman (1989)\n",
            "Pinocchio (1940)\n",
            "Mission: Impossible (1996)\n",
            "Thinner (1996)\n",
            "Spy Hard (1996)\n",
            "Close Shave, A (1995)\n",
            "Jack (1996)\n",
            "Kingpin (1996)\n",
            "Nutty Professor, The (1996)\n",
            "Very Brady Sequel, A (1996)\n",
            "Tales from the Crypt Presents: Bordello of Blood (1996)\n",
            "My Favorite Year (1982)\n",
            "Apple Dumpling Gang, The (1975)\n",
            "Old Yeller (1957)\n",
            "Parent Trap, The (1961)\n",
            "Cinderella (1950)\n",
            "Mary Poppins (1964)\n",
            "Alice in Wonderland (1951)\n",
            "William Shakespeare's Romeo and Juliet (1996)\n",
            "Aladdin and the King of Thieves (1996)\n",
            "E.T. the Extra-Terrestrial (1982)\n",
            "Children of the Corn: The Gathering (1996)\n",
            "Bob Roberts (1992)\n",
            "Transformers: The Movie, The (1986)\n",
            "To Kill a Mockingbird (1962)\n",
            "Harold and Maude (1971)\n",
            "Day the Earth Stood Still, The (1951)\n",
            "Duck Soup (1933)\n",
            "Highlander (1986)\n",
            "Fantasia (1940)\n",
            "Heathers (1989)\n",
            "Forbidden Planet (1956)\n",
            "Butch Cassidy and the Sundance Kid (1969)\n",
            "American Werewolf in London, An (1981)\n",
            "Amityville 1992: It's About Time (1992)\n",
            "Amityville 3-D (1983)\n",
            "Amityville: A New Generation (1993)\n",
            "Amityville II: The Possession (1982)\n",
            "Amityville Horror, The (1979)\n",
            "Amityville Curse, The (1990)\n",
            "Birds, The (1963)\n",
            "Blob, The (1958)\n",
            "Body Snatcher, The (1945)\n",
            "Burnt Offerings (1976)\n",
            "Carrie (1976)\n",
            "Omen, The (1976)\n",
            "Star Trek: The Motion Picture (1979)\n",
            "Star Trek V: The Final Frontier (1989)\n",
            "Grease (1978)\n",
            "Jaws 2 (1978)\n",
            "Jaws 3-D (1983)\n",
            "Bastard Out of Carolina (1996)\n",
            "Jackie Chan's First Strike (1996)\n",
            "Beverly Hills Ninja (1997)\n",
            "Free Willy 3: The Rescue (1997)\n",
            "Nixon (1995)\n",
            "Cry, the Beloved Country (1995)\n",
            "Crossing Guard, The (1995)\n",
            "Smoke (1995)\n",
            "Like Water For Chocolate (Como agua para chocolate) (1992)\n",
            "Secret of Roan Inish, The (1994)\n",
            "Vanya on 42nd Street (1994)\n",
            "Jungle Book, The (1994)\n",
            "Red Rock West (1992)\n",
            "Bronx Tale, A (1993)\n",
            "Rudy (1993)\n",
            "Short Cuts (1993)\n",
            "Tombstone (1993)\n",
            "Courage Under Fire (1996)\n",
            "Dragonheart (1996)\n",
            "James and the Giant Peach (1996)\n",
            "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\n",
            "Trainspotting (1996)\n",
            "First Wives Club, The (1996)\n",
            "Matilda (1996)\n",
            "Philadelphia Story, The (1940)\n",
            "Vertigo (1958)\n",
            "North by Northwest (1959)\n",
            "Apartment, The (1960)\n",
            "Some Like It Hot (1959)\n",
            "Casablanca (1942)\n",
            "Maltese Falcon, The (1941)\n",
            "My Fair Lady (1964)\n",
            "Sabrina (1954)\n",
            "Roman Holiday (1953)\n",
            "Sunset Blvd. (1950)\n",
            "Notorious (1946)\n",
            "To Catch a Thief (1955)\n",
            "Adventures of Robin Hood, The (1938)\n",
            "East of Eden (1955)\n",
            "Thin Man, The (1934)\n",
            "His Girl Friday (1940)\n",
            "Around the World in 80 Days (1956)\n",
            "It's a Wonderful Life (1946)\n",
            "Bringing Up Baby (1938)\n",
            "African Queen, The (1951)\n",
            "Cat on a Hot Tin Roof (1958)\n",
            "Dumbo (1941)\n",
            "Bananas (1971)\n",
            "Candidate, The (1972)\n",
            "Bonnie and Clyde (1967)\n",
            "Dial M for Murder (1954)\n",
            "Rebel Without a Cause (1955)\n",
            "Streetcar Named Desire, A (1951)\n",
            "People vs. Larry Flynt, The (1996)\n",
            "My Left Foot (1989)\n",
            "Magnificent Seven, The (1954)\n",
            "Lawrence of Arabia (1962)\n",
            "Wings of Desire (1987)\n",
            "Third Man, The (1949)\n",
            "Annie Hall (1977)\n",
            "Boot, Das (1981)\n",
            "Local Hero (1983)\n",
            "Manhattan (1979)\n",
            "Miller's Crossing (1990)\n",
            "Treasure of the Sierra Madre, The (1948)\n",
            "Great Escape, The (1963)\n",
            "Deer Hunter, The (1978)\n",
            "Down by Law (1986)\n",
            "Cool Hand Luke (1967)\n",
            "Great Dictator, The (1940)\n",
            "Big Sleep, The (1946)\n",
            "Ben-Hur (1959)\n",
            "Gandhi (1982)\n",
            "Killing Fields, The (1984)\n",
            "My Life as a Dog (Mitt liv som hund) (1985)\n",
            "Man Who Would Be King, The (1975)\n",
            "Shine (1996)\n",
            "Kama Sutra: A Tale of Love (1996)\n",
            "Daytrippers, The (1996)\n",
            "Traveller (1997)\n",
            "Addicted to Love (1997)\n",
            "Ponette (1996)\n",
            "My Own Private Idaho (1991)\n",
            "Anastasia (1997)\n",
            "Mouse Hunt (1997)\n",
            "Money Train (1995)\n",
            "Mortal Kombat (1995)\n",
            "Pocahontas (1995)\n",
            "Misrables, Les (1995)\n",
            "Things to Do in Denver when You're Dead (1995)\n",
            "Vampire in Brooklyn (1995)\n",
            "Broken Arrow (1996)\n",
            "Young Poisoner's Handbook, The (1995)\n",
            "NeverEnding Story III, The (1994)\n",
            "Rob Roy (1995)\n",
            "Die Hard: With a Vengeance (1995)\n",
            "Lord of Illusions (1995)\n",
            "Species (1995)\n",
            "Walk in the Clouds, A (1995)\n",
            "Waterworld (1995)\n",
            "White Man's Burden (1995)\n",
            "Wild Bill (1995)\n",
            "Farinelli: il castrato (1994)\n",
            "Heavenly Creatures (1994)\n",
            "Interview with the Vampire (1994)\n",
            "Kid in King Arthur's Court, A (1995)\n",
            "Mary Shelley's Frankenstein (1994)\n",
            "Quick and the Dead, The (1995)\n",
            "Stephen King's The Langoliers (1995)\n",
            "Tales from the Hood (1995)\n",
            "Village of the Damned (1995)\n",
            "Clear and Present Danger (1994)\n",
            "Wes Craven's New Nightmare (1994)\n",
            "Speed (1994)\n",
            "Wolf (1994)\n",
            "Wyatt Earp (1994)\n",
            "Another Stakeout (1993)\n",
            "Blown Away (1994)\n",
            "Body Snatchers (1993)\n",
            "Boxing Helena (1993)\n",
            "City Slickers II: The Legend of Curly's Gold (1994)\n",
            "Cliffhanger (1993)\n",
            "Coneheads (1993)\n",
            "Demolition Man (1993)\n",
            "Fatal Instinct (1993)\n",
            "Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)\n",
            "Kalifornia (1993)\n",
            "Piano, The (1993)\n",
            "Romeo Is Bleeding (1993)\n",
            "Secret Garden, The (1993)\n",
            "Son in Law (1993)\n",
            "Terminal Velocity (1994)\n",
            "Hour of the Pig, The (1993)\n",
            "Beauty and the Beast (1991)\n",
            "Wild Bunch, The (1969)\n",
            "Hellraiser: Bloodline (1996)\n",
            "Primal Fear (1996)\n",
            "True Crime (1995)\n",
            "Stalingrad (1993)\n",
            "Heavy (1995)\n",
            "Fan, The (1996)\n",
            "Hunchback of Notre Dame, The (1996)\n",
            "Eraser (1996)\n",
            "Big Squeeze, The (1996)\n",
            "Police Story 4: Project S (Chao ji ji hua) (1993)\n",
            "Daniel Defoe's Robinson Crusoe (1996)\n",
            "For Whom the Bell Tolls (1943)\n",
            "American in Paris, An (1951)\n",
            "Rear Window (1954)\n",
            "It Happened One Night (1934)\n",
            "Meet Me in St. Louis (1944)\n",
            "All About Eve (1950)\n",
            "Rebecca (1940)\n",
            "Spellbound (1945)\n",
            "Father of the Bride (1950)\n",
            "Gigi (1958)\n",
            "Laura (1944)\n",
            "Lost Horizon (1937)\n",
            "My Man Godfrey (1936)\n",
            "Giant (1956)\n",
            "39 Steps, The (1935)\n",
            "Night of the Living Dead (1968)\n",
            "Blue Angel, The (Blaue Engel, Der) (1930)\n",
            "Picnic (1955)\n",
            "Extreme Measures (1996)\n",
            "Chamber, The (1996)\n",
            "Davy Crockett, King of the Wild Frontier (1955)\n",
            "Swiss Family Robinson (1960)\n",
            "Angels in the Outfield (1994)\n",
            "Three Caballeros, The (1945)\n",
            "Sword in the Stone, The (1963)\n",
            "So Dear to My Heart (1949)\n",
            "Robin Hood: Prince of Thieves (1991)\n",
            "Sleepers (1996)\n",
            "Victor/Victoria (1982)\n",
            "Great Race, The (1965)\n",
            "Crying Game, The (1992)\n",
            "Sophie's Choice (1982)\n",
            "Christmas Carol, A (1938)\n",
            "Microcosmos: Le peuple de l'herbe (1996)\n",
            "Fog, The (1980)\n",
            "Escape from New York (1981)\n",
            "Howling, The (1981)\n",
            "Return of Martin Guerre, The (Retour de Martin Guerre, Le) (1982)\n",
            "Tin Drum, The (Blechtrommel, Die) (1979)\n",
            "Cook the Thief His Wife & Her Lover, The (1989)\n",
            "Paths of Glory (1957)\n",
            "Grifters, The (1990)\n",
            "The Innocent (1994)\n",
            "Thin Blue Line, The (1988)\n",
            "Paris Is Burning (1990)\n",
            "Once Upon a Time in the West (1969)\n",
            "Ran (1985)\n",
            "Quiet Man, The (1952)\n",
            "Once Upon a Time in America (1984)\n",
            "Seventh Seal, The (Sjunde inseglet, Det) (1957)\n",
            "Glory (1989)\n",
            "Rosencrantz and Guildenstern Are Dead (1990)\n",
            "Touch of Evil (1958)\n",
            "Chinatown (1974)\n",
            "Stand by Me (1986)\n",
            "M (1931)\n",
            "Manchurian Candidate, The (1962)\n",
            "Pump Up the Volume (1990)\n",
            "Arsenic and Old Lace (1944)\n",
            "Fried Green Tomatoes (1991)\n",
            "High Noon (1952)\n",
            "Somewhere in Time (1980)\n",
            "Being There (1979)\n",
            "Paris, Texas (1984)\n",
            "Alien 3 (1992)\n",
            "Blood For Dracula (Andy Warhol's Dracula) (1974)\n",
            "Audrey Rose (1977)\n",
            "Blood Beach (1981)\n",
            "Body Parts (1991)\n",
            "Bride of Frankenstein (1935)\n",
            "Candyman (1992)\n",
            "Cape Fear (1962)\n",
            "Cat People (1982)\n",
            "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)\n",
            "Crucible, The (1996)\n",
            "Fire on the Mountain (1996)\n",
            "Volcano (1997)\n",
            "Conan the Barbarian (1981)\n",
            "Wishmaster (1997)\n",
            "I Know What You Did Last Summer (1997)\n",
            "Rocket Man (1997)\n",
            "In the Line of Fire (1993)\n",
            "Executive Decision (1996)\n",
            "Perfect World, A (1993)\n",
            "McHale's Navy (1997)\n",
            "Leave It to Beaver (1997)\n",
            "Jackal, The (1997)\n",
            "Seven Years in Tibet (1997)\n",
            "Dark City (1998)\n",
            "American President, The (1995)\n",
            "Casino (1995)\n",
            "Persuasion (1995)\n",
            "Kicking and Screaming (1995)\n",
            "City Hall (1996)\n",
            "Basketball Diaries, The (1995)\n",
            "Browning Version, The (1994)\n",
            "Little Women (1994)\n",
            "Miami Rhapsody (1995)\n",
            "Wonderful, Horrible Life of Leni Riefenstahl, The (1993)\n",
            "Barcelona (1994)\n",
            "Widows' Peak (1994)\n",
            "House of the Spirits, The (1993)\n",
            "Singin' in the Rain (1952)\n",
            "Bad Moon (1996)\n",
            "Enchanted April (1991)\n",
            "Sex, Lies, and Videotape (1989)\n",
            "Strictly Ballroom (1992)\n",
            "Better Off Dead... (1985)\n",
            "Substance of Fire, The (1996)\n",
            "Tin Men (1987)\n",
            "Othello (1995)\n",
            "Carrington (1995)\n",
            "To Die For (1995)\n",
            "Home for the Holidays (1995)\n",
            "Juror, The (1996)\n",
            "In the Bleak Midwinter (1995)\n",
            "Canadian Bacon (1994)\n",
            "First Knight (1995)\n",
            "Mallrats (1995)\n",
            "Nine Months (1995)\n",
            "Boys on the Side (1995)\n",
            "Circle of Friends (1995)\n",
            "Exit to Eden (1994)\n",
            "Fluke (1995)\n",
            "Immortal Beloved (1994)\n",
            "Junior (1994)\n",
            "Nell (1994)\n",
            "Queen Margot (Reine Margot, La) (1994)\n",
            "Corrina, Corrina (1994)\n",
            "Dave (1993)\n",
            "Go Fish (1994)\n",
            "Made in America (1993)\n",
            "Philadelphia (1993)\n",
            "Shadowlands (1993)\n",
            "Sirens (1994)\n",
            "Threesome (1994)\n",
            "Pretty Woman (1990)\n",
            "Jane Eyre (1996)\n",
            "Last Supper, The (1995)\n",
            "Ransom (1996)\n",
            "Crow: City of Angels, The (1996)\n",
            "Michael Collins (1996)\n",
            "Ruling Class, The (1972)\n",
            "Real Genius (1985)\n",
            "Benny & Joon (1993)\n",
            "Saint, The (1997)\n",
            "MatchMaker, The (1997)\n",
            "Amistad (1997)\n",
            "Tomorrow Never Dies (1997)\n",
            "Replacement Killers, The (1998)\n",
            "Burnt By the Sun (1994)\n",
            "Red Corner (1997)\n",
            "Jumanji (1995)\n",
            "Father of the Bride Part II (1995)\n",
            "Across the Sea of Time (1995)\n",
            "Lawnmower Man 2: Beyond Cyberspace (1996)\n",
            "Fair Game (1995)\n",
            "Screamers (1995)\n",
            "Nick of Time (1995)\n",
            "Beautiful Girls (1996)\n",
            "Happy Gilmore (1996)\n",
            "If Lucy Fell (1996)\n",
            "Boomerang (1992)\n",
            "Man of the Year (1995)\n",
            "Addiction, The (1995)\n",
            "Casper (1995)\n",
            "Congo (1995)\n",
            "Devil in a Blue Dress (1995)\n",
            "Johnny Mnemonic (1995)\n",
            "Kids (1995)\n",
            "Mute Witness (1994)\n",
            "Prophecy, The (1995)\n",
            "Something to Talk About (1995)\n",
            "Three Wishes (1995)\n",
            "Castle Freak (1995)\n",
            "Don Juan DeMarco (1995)\n",
            "Drop Zone (1994)\n",
            "Dumb & Dumber (1994)\n",
            "French Kiss (1995)\n",
            "Little Odessa (1994)\n",
            "Milk Money (1994)\n",
            "Beyond Bedlam (1993)\n",
            "Only You (1994)\n",
            "Perez Family, The (1995)\n",
            "Roommates (1995)\n",
            "Relative Fear (1994)\n",
            "Swimming with Sharks (1995)\n",
            "Tommy Boy (1995)\n",
            "Baby-Sitters Club, The (1995)\n",
            "Bullets Over Broadway (1994)\n",
            "Crooklyn (1994)\n",
            "It Could Happen to You (1994)\n",
            "Richie Rich (1994)\n",
            "Speechless (1994)\n",
            "Timecop (1994)\n",
            "Bad Company (1995)\n",
            "Boys Life (1995)\n",
            "In the Mouth of Madness (1995)\n",
            "Air Up There, The (1994)\n",
            "Hard Target (1993)\n",
            "Heaven & Earth (1993)\n",
            "Jimmy Hollywood (1994)\n",
            "Manhattan Murder Mystery (1993)\n",
            "Menace II Society (1993)\n",
            "Poetic Justice (1993)\n",
            "Program, The (1993)\n",
            "Rising Sun (1993)\n",
            "Shadow, The (1994)\n",
            "Thirty-Two Short Films About Glenn Gould (1993)\n",
            "Andre (1994)\n",
            "Celluloid Closet, The (1995)\n",
            "Great Day in Harlem, A (1994)\n",
            "One Fine Day (1996)\n",
            "Candyman: Farewell to the Flesh (1995)\n",
            "Frisk (1995)\n",
            "Girl 6 (1996)\n",
            "Eddie (1996)\n",
            "Space Jam (1996)\n",
            "Mrs. Winterbourne (1996)\n",
            "Faces (1968)\n",
            "Mulholland Falls (1996)\n",
            "Great White Hype, The (1996)\n",
            "Arrival, The (1996)\n",
            "Phantom, The (1996)\n",
            "Daylight (1996)\n",
            "Alaska (1996)\n",
            "Fled (1996)\n",
            "Power 98 (1995)\n",
            "Escape from L.A. (1996)\n",
            "Bogus (1996)\n",
            "Bulletproof (1996)\n",
            "Halloween: The Curse of Michael Myers (1995)\n",
            "Gay Divorcee, The (1934)\n",
            "Ninotchka (1939)\n",
            "Meet John Doe (1941)\n",
            "In the Line of Duty 2 (1987)\n",
            "Loch Ness (1995)\n",
            "Last Man Standing (1996)\n",
            "Glimmer Man, The (1996)\n",
            "Pollyanna (1960)\n",
            "Shaggy Dog, The (1959)\n",
            "Freeway (1996)\n",
            "That Thing You Do! (1996)\n",
            "To Gillian on Her 37th Birthday (1996)\n",
            "Looking for Richard (1996)\n",
            "Murder, My Sweet (1944)\n",
            "Days of Thunder (1990)\n",
            "Perfect Candidate, A (1996)\n",
            "Two or Three Things I Know About Her (1966)\n",
            "Bloody Child, The (1996)\n",
            "Braindead (1992)\n",
            "Bad Taste (1987)\n",
            "Diva (1981)\n",
            "Night on Earth (1991)\n",
            "Paris Was a Woman (1995)\n",
            "Amityville: Dollhouse (1996)\n",
            "April Fool's Day (1986)\n",
            "Believers, The (1987)\n",
            "Nosferatu a Venezia (1986)\n",
            "Jingle All the Way (1996)\n",
            "Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)\n",
            "My Fellow Americans (1996)\n",
            "Michael (1996)\n",
            "Whole Wide World, The (1996)\n",
            "Hearts and Minds (1996)\n",
            "Fools Rush In (1997)\n",
            "Touch (1997)\n",
            "Vegas Vacation (1997)\n",
            "Love Jones (1997)\n",
            "Picture Perfect (1997)\n",
            "Career Girls (1997)\n",
            "She's So Lovely (1997)\n",
            "Money Talks (1997)\n",
            "Excess Baggage (1997)\n",
            "That Darn Cat! (1997)\n",
            "Peacemaker, The (1997)\n",
            "Soul Food (1997)\n",
            "Washington Square (1997)\n",
            "Telling Lies in America (1997)\n",
            "Year of the Horse (1997)\n",
            "Phantoms (1998)\n",
            "Life Less Ordinary, A (1997)\n",
            "Eve's Bayou (1997)\n",
            "One Night Stand (1997)\n",
            "Tango Lesson, The (1997)\n",
            "Mortal Kombat: Annihilation (1997)\n",
            "Bent (1997)\n",
            "Flubber (1997)\n",
            "For Richer or Poorer (1997)\n",
            "Home Alone 3 (1997)\n",
            "Scream 2 (1997)\n",
            "Sweet Hereafter, The (1997)\n",
            "Time Tracers (1995)\n",
            "Postman, The (1997)\n",
            "Winter Guest, The (1997)\n",
            "Kundun (1997)\n",
            "Mr. Magoo (1997)\n",
            "Big Lebowski, The (1998)\n",
            "Afterglow (1997)\n",
            "Ma vie en rose (My Life in Pink) (1997)\n",
            "Great Expectations (1998)\n",
            "Oscar & Lucinda (1997)\n",
            "Vermin (1998)\n",
            "Half Baked (1998)\n",
            "Dangerous Beauty (1998)\n",
            "Nil By Mouth (1997)\n",
            "Twilight (1998)\n",
            "U.S. Marshalls (1998)\n",
            "Love and Death on Long Island (1997)\n",
            "Wild Things (1998)\n",
            "Primary Colors (1998)\n",
            "Lost in Space (1998)\n",
            "Mercury Rising (1998)\n",
            "City of Angels (1998)\n",
            "City of Lost Children, The (1995)\n",
            "Two Bits (1995)\n",
            "Farewell My Concubine (1993)\n",
            "Dead Man (1995)\n",
            "Raise the Red Lantern (1991)\n",
            "White Squall (1996)\n",
            "Unforgettable (1996)\n",
            "Down Periscope (1996)\n",
            "Flower of My Secret, The (Flor de mi secreto, La) (1995)\n",
            "Craft, The (1996)\n",
            "Harriet the Spy (1996)\n",
            "Chain Reaction (1996)\n",
            "Island of Dr. Moreau, The (1996)\n",
            "First Kid (1996)\n",
            "Funeral, The (1996)\n",
            "Preacher's Wife, The (1996)\n",
            "Paradise Road (1997)\n",
            "Brassed Off (1996)\n",
            "Thousand Acres, A (1997)\n",
            "Smile Like Yours, A (1997)\n",
            "Murder in the First (1995)\n",
            "Airheads (1994)\n",
            "With Honors (1994)\n",
            "What's Love Got to Do with It (1993)\n",
            "Killing Zoe (1994)\n",
            "Renaissance Man (1994)\n",
            "Charade (1963)\n",
            "Fox and the Hound, The (1981)\n",
            "Big Blue, The (Grand bleu, Le) (1988)\n",
            "Booty Call (1997)\n",
            "How to Make an American Quilt (1995)\n",
            "Georgia (1995)\n",
            "Indian in the Cupboard, The (1995)\n",
            "Blue in the Face (1995)\n",
            "Unstrung Heroes (1995)\n",
            "Unzipped (1995)\n",
            "Before Sunrise (1995)\n",
            "Nobody's Fool (1994)\n",
            "Pushing Hands (1992)\n",
            "To Live (Huozhe) (1994)\n",
            "Dazed and Confused (1993)\n",
            "Naked (1993)\n",
            "Orlando (1993)\n",
            "Ruby in Paradise (1993)\n",
            "Some Folks Call It a Sling Blade (1993)\n",
            "Month by the Lake, A (1995)\n",
            "Funny Face (1957)\n",
            "Affair to Remember, An (1957)\n",
            "Little Lord Fauntleroy (1936)\n",
            "Inspector General, The (1949)\n",
            "Winnie the Pooh and the Blustery Day (1968)\n",
            "Hear My Song (1991)\n",
            "Mediterraneo (1991)\n",
            "Passion Fish (1992)\n",
            "Grateful Dead (1995)\n",
            "Eye for an Eye (1996)\n",
            "Fear (1996)\n",
            "Solo (1996)\n",
            "Substitute, The (1996)\n",
            "Heaven's Prisoners (1996)\n",
            "Trigger Effect, The (1996)\n",
            "Mother Night (1996)\n",
            "Dangerous Ground (1997)\n",
            "Maximum Risk (1996)\n",
            "Rich Man's Wife, The (1996)\n",
            "Shadow Conspiracy (1997)\n",
            "Blood & Wine (1997)\n",
            "Turbulence (1997)\n",
            "Underworld (1997)\n",
            "Beautician and the Beast, The (1997)\n",
            "Cats Don't Dance (1997)\n",
            "Anna Karenina (1997)\n",
            "Keys to Tulsa (1997)\n",
            "Head Above Water (1996)\n",
            "Hercules (1997)\n",
            "Last Time I Committed Suicide, The (1997)\n",
            "Kiss Me, Guido (1997)\n",
            "Big Green, The (1995)\n",
            "Stuart Saves His Family (1995)\n",
            "Cabin Boy (1994)\n",
            "Clean Slate (1994)\n",
            "Lightning Jack (1994)\n",
            "Stupids, The (1996)\n",
            "Pest, The (1997)\n",
            "Geronimo: An American Legend (1993)\n",
            "Double vie de Vronique, La (Double Life of Veronique, The) (1991)\n",
            "Until the End of the World (Bis ans Ende der Welt) (1991)\n",
            "Waiting for Guffman (1996)\n",
            "I Shot Andy Warhol (1996)\n",
            "Stealing Beauty (1996)\n",
            "Basquiat (1996)\n",
            "2 Days in the Valley (1996)\n",
            "Private Parts (1997)\n",
            "Anaconda (1997)\n",
            "Romy and Michele's High School Reunion (1997)\n",
            "Shiloh (1997)\n",
            "Con Air (1997)\n",
            "Trees Lounge (1996)\n",
            "Tie Me Up! Tie Me Down! (1990)\n",
            "Die xue shuang xiong (Killer, The) (1989)\n",
            "Gaslight (1944)\n",
            "8 1/2 (1963)\n",
            "Fast, Cheap & Out of Control (1997)\n",
            "Fathers' Day (1997)\n",
            "Mrs. Dalloway (1997)\n",
            "Fire Down Below (1997)\n",
            "Lay of the Land, The (1997)\n",
            "Shooter, The (1995)\n",
            "Grumpier Old Men (1995)\n",
            "Jury Duty (1995)\n",
            "Beverly Hillbillies, The (1993)\n",
            "Lassie (1994)\n",
            "Little Big League (1994)\n",
            "Homeward Bound II: Lost in San Francisco (1996)\n",
            "Quest, The (1996)\n",
            "Cool Runnings (1993)\n",
            "Drop Dead Fred (1991)\n",
            "Grease 2 (1982)\n",
            "Switchback (1997)\n",
            "Hamlet (1996)\n",
            "Two if by Sea (1996)\n",
            "Forget Paris (1995)\n",
            "Just Cause (1995)\n",
            "Rent-a-Kid (1995)\n",
            "Paper, The (1994)\n",
            "Fearless (1993)\n",
            "Malice (1993)\n",
            "Multiplicity (1996)\n",
            "She's the One (1996)\n",
            "House Arrest (1996)\n",
            "Ghost and Mrs. Muir, The (1947)\n",
            "Associate, The (1996)\n",
            "Dracula: Dead and Loving It (1995)\n",
            "Now and Then (1995)\n",
            "Mr. Wrong (1996)\n",
            "Simple Twist of Fate, A (1994)\n",
            "Cronos (1992)\n",
            "Pallbearer, The (1996)\n",
            "War, The (1994)\n",
            "Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\n",
            "Adventures of Pinocchio, The (1996)\n",
            "Evening Star, The (1996)\n",
            "Four Days in September (1997)\n",
            "Little Princess, A (1995)\n",
            "Crossfire (1947)\n",
            "Koyaanisqatsi (1983)\n",
            "Balto (1995)\n",
            "Bottle Rocket (1996)\n",
            "Star Maker, The (Uomo delle stelle, L') (1995)\n",
            "Amateur (1994)\n",
            "Living in Oblivion (1995)\n",
            "Party Girl (1995)\n",
            "Pyromaniac's Love Story, A (1995)\n",
            "Shallow Grave (1994)\n",
            "Reality Bites (1994)\n",
            "Man of No Importance, A (1994)\n",
            "Pagemaster, The (1994)\n",
            "Love and a .45 (1994)\n",
            "Oliver & Company (1988)\n",
            "Joe's Apartment (1996)\n",
            "Celestial Clockwork (1994)\n",
            "Curdled (1996)\n",
            "Female Perversions (1996)\n",
            "Albino Alligator (1996)\n",
            "Anne Frank Remembered (1995)\n",
            "Carried Away (1996)\n",
            "It's My Party (1995)\n",
            "Bloodsport 2 (1995)\n",
            "Double Team (1997)\n",
            "Speed 2: Cruise Control (1997)\n",
            "Sliver (1993)\n",
            "Pete's Dragon (1977)\n",
            "Dear God (1996)\n",
            "Live Nude Girls (1995)\n",
            "Thin Line Between Love and Hate, A (1996)\n",
            "High School High (1996)\n",
            "Commandments (1997)\n",
            "Hate (Haine, La) (1995)\n",
            "Flirting With Disaster (1996)\n",
            "Red Firecracker, Green Firecracker (1994)\n",
            "What Happened Was... (1994)\n",
            "Six Degrees of Separation (1993)\n",
            "Two Much (1996)\n",
            "Trust (1990)\n",
            "C'est arriv prs de chez vous (1992)\n",
            "Firestorm (1998)\n",
            "Newton Boys, The (1998)\n",
            "Beyond Rangoon (1995)\n",
            "Feast of July (1995)\n",
            "Death and the Maiden (1994)\n",
            "Tank Girl (1995)\n",
            "Double Happiness (1994)\n",
            "Cobb (1994)\n",
            "Mrs. Parker and the Vicious Circle (1994)\n",
            "Faithful (1996)\n",
            "Twelfth Night (1996)\n",
            "Mark of Zorro, The (1940)\n",
            "Surviving Picasso (1996)\n",
            "Up in Smoke (1978)\n",
            "Some Kind of Wonderful (1987)\n",
            "I'm Not Rappaport (1996)\n",
            "Umbrellas of Cherbourg, The (Parapluies de Cherbourg, Les) (1964)\n",
            "They Made Me a Criminal (1939)\n",
            "Last Time I Saw Paris, The (1954)\n",
            "Farewell to Arms, A (1932)\n",
            "Innocents, The (1961)\n",
            "Old Man and the Sea, The (1958)\n",
            "Truman Show, The (1998)\n",
            "Heidi Fleiss: Hollywood Madam (1995) \n",
            "Chungking Express (1994)\n",
            "Jupiter's Wife (1994)\n",
            "Safe (1995)\n",
            "Feeling Minnesota (1996)\n",
            "Escape to Witch Mountain (1975)\n",
            "Get on the Bus (1996)\n",
            "Doors, The (1991)\n",
            "Ghosts of Mississippi (1996)\n",
            "Beautiful Thing (1996)\n",
            "Best Men (1997)\n",
            "Hackers (1995)\n",
            "Road to Wellville, The (1994)\n",
            "War Room, The (1993)\n",
            "When We Were Kings (1996)\n",
            "Hard Eight (1996)\n",
            "Quiet Room, The (1996)\n",
            "Blue Chips (1994)\n",
            "Calendar Girl (1993)\n",
            "My Family (1995)\n",
            "Tom & Viv (1994)\n",
            "Walkabout (1971)\n",
            "Last Dance (1996)\n",
            "Original Gangstas (1996)\n",
            "In Love and War (1996)\n",
            "Backbeat (1993)\n",
            "Alphaville (1965)\n",
            "Rendezvous in Paris (Rendez-vous de Paris, Les) (1995)\n",
            "Cyclo (1995)\n",
            "Relic, The (1997)\n",
            "Fille seule, La (A Single Girl) (1995)\n",
            "Stalker (1979)\n",
            "Love! Valour! Compassion! (1997)\n",
            "Palookaville (1996)\n",
            "Phat Beach (1996)\n",
            "Portrait of a Lady, The (1996)\n",
            "Zeus and Roxanne (1997)\n",
            "Big Bully (1996)\n",
            "Love & Human Remains (1993)\n",
            "Sum of Us, The (1994)\n",
            "Little Buddha (1993)\n",
            "Fresh (1994)\n",
            "Spanking the Monkey (1994)\n",
            "Wild Reeds (1994)\n",
            "Women, The (1939)\n",
            "Bliss (1997)\n",
            "Caught (1996)\n",
            "Hugo Pool (1997)\n",
            "Welcome To Sarajevo (1997)\n",
            "Dunston Checks In (1996)\n",
            "Major Payne (1994)\n",
            "Man of the House (1995)\n",
            "I Love Trouble (1994)\n",
            "Low Down Dirty Shame, A (1994)\n",
            "Cops and Robbersons (1994)\n",
            "Cowboy Way, The (1994)\n",
            "Endless Summer 2, The (1994)\n",
            "In the Army Now (1994)\n",
            "Inkwell, The (1994)\n",
            "Switchblade Sisters (1975)\n",
            "Young Guns II (1990)\n",
            "Prefontaine (1997)\n",
            "That Old Feeling (1997)\n",
            "Letter From Death Row, A (1998)\n",
            "Boys of St. Vincent, The (1993)\n",
            "Before the Rain (Pred dozhdot) (1994)\n",
            "Once Were Warriors (1994)\n",
            "Strawberry and Chocolate (Fresa y chocolate) (1993)\n",
            "Savage Nights (Nuits fauves, Les) (1992)\n",
            "Family Thing, A (1996)\n",
            "Purple Noon (1960)\n",
            "Cemetery Man (Dellamorte Dellamore) (1994)\n",
            "Kim (1950)\n",
            "Marlene Dietrich: Shadow and Light (1996) \n",
            "Maybe, Maybe Not (Bewegte Mann, Der) (1994)\n",
            "Top Hat (1935)\n",
            "To Be or Not to Be (1942)\n",
            "Secret Agent, The (1996)\n",
            "Amos & Andrew (1993)\n",
            "Jade (1995)\n",
            "Kiss of Death (1995)\n",
            "Mixed Nuts (1994)\n",
            "Virtuosity (1995)\n",
            "Blue Sky (1994)\n",
            "Flesh and Bone (1993)\n",
            "Guilty as Sin (1993)\n",
            "In the Realm of the Senses (Ai no corrida) (1976)\n",
            "Barb Wire (1996)\n",
            "Kissed (1996)\n",
            "Assassins (1995)\n",
            "Friday (1995)\n",
            "Goofy Movie, A (1995)\n",
            "Higher Learning (1995)\n",
            "When a Man Loves a Woman (1994)\n",
            "Judgment Night (1993)\n",
            "King of the Hill (1993)\n",
            "Scout, The (1994)\n",
            "Angus (1995)\n",
            "Night Falls on Manhattan (1997)\n",
            "Awfully Big Adventure, An (1995)\n",
            "Under Siege 2: Dark Territory (1995)\n",
            "Poison Ivy II (1995)\n",
            "Ready to Wear (Pret-A-Porter) (1994)\n",
            "Marked for Death (1990)\n",
            "Madonna: Truth or Dare (1991)\n",
            "Nnette et Boni (1996)\n",
            "Chairman of the Board (1998)\n",
            "Big Bang Theory, The (1994)\n",
            "Other Voices, Other Rooms (1997)\n",
            "Twisted (1996)\n",
            "Full Speed (1996)\n",
            "Cutthroat Island (1995)\n",
            "Ghost in the Shell (Kokaku kidotai) (1995)\n",
            "Van, The (1996)\n",
            "Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)\n",
            "Night Flier (1997)\n",
            "Metro (1997)\n",
            "Gridlock'd (1997)\n",
            "Bushwhacked (1995)\n",
            "Bad Girls (1994)\n",
            "Blink (1994)\n",
            "For Love or Money (1993)\n",
            "Best of the Best 3: No Turning Back (1995)\n",
            "A Chef in Love (1996)\n",
            "Contempt (Mpris, Le) (1963)\n",
            "Tie That Binds, The (1995)\n",
            "Gone Fishin' (1997)\n",
            "Broken English (1996)\n",
            "Designated Mourner, The (1997)\n",
            "Trial and Error (1997)\n",
            "Pie in the Sky (1995)\n",
            "Total Eclipse (1995)\n",
            "Run of the Country, The (1995)\n",
            "Walking and Talking (1996)\n",
            "Foxfire (1996)\n",
            "Nothing to Lose (1994)\n",
            "Star Maps (1997)\n",
            "Bread and Chocolate (Pane e cioccolata) (1973)\n",
            "Clockers (1995)\n",
            "Bitter Moon (1992)\n",
            "Love in the Afternoon (1957)\n",
            "Life with Mikey (1993)\n",
            "North (1994)\n",
            "Talking About Sex (1994)\n",
            "Color of Night (1994)\n",
            "Robocop 3 (1993)\n",
            "Killer (Bulletproof Heart) (1994)\n",
            "Sunset Park (1996)\n",
            "Set It Off (1996)\n",
            "Selena (1997)\n",
            "Wild America (1997)\n",
            "Gang Related (1997)\n",
            "Manny & Lo (1996)\n",
            "Grass Harp, The (1995)\n",
            "Out to Sea (1997)\n",
            "Before and After (1996)\n",
            "Princess Caraboo (1994)\n",
            "Shall We Dance? (1937)\n",
            "Ed (1996)\n",
            "Denise Calls Up (1995)\n",
            "Jack and Sarah (1995)\n",
            "Country Life (1994)\n",
            "Celtic Pride (1996)\n",
            "Simple Wish, A (1997)\n",
            "Star Kid (1997)\n",
            "Ayn Rand: A Sense of Life (1997)\n",
            "Kicked in the Head (1997)\n",
            "Indian Summer (1996)\n",
            "Love Affair (1994)\n",
            "Band Wagon, The (1953)\n",
            "Penny Serenade (1941)\n",
            "'Til There Was You (1997)\n",
            "Stripes (1981)\n",
            "Late Bloomers (1996)\n",
            "Getaway, The (1994)\n",
            "New York Cop (1996)\n",
            "National Lampoon's Senior Trip (1995)\n",
            "Delta of Venus (1994)\n",
            "Carmen Miranda: Bananas Is My Business (1994)\n",
            "Babyfever (1994)\n",
            "Very Natural Thing, A (1974)\n",
            "Walk in the Sun, A (1945)\n",
            "Waiting to Exhale (1995)\n",
            "Pompatus of Love, The (1996)\n",
            "Palmetto (1998)\n",
            "Surviving the Game (1994)\n",
            "Inventing the Abbotts (1997)\n",
            "Horse Whisperer, The (1998)\n",
            "Journey of August King, The (1995)\n",
            "Catwalk (1995)\n",
            "Neon Bible, The (1995)\n",
            "Homage (1995)\n",
            "Open Season (1996)\n",
            "Metisse (Caf au Lait) (1993)\n",
            "Wooden Man's Bride, The (Wu Kui) (1994)\n",
            "Loaded (1994)\n",
            "August (1996)\n",
            "Boys (1996)\n",
            "Captives (1994)\n",
            "Of Love and Shadows (1994)\n",
            "Low Life, The (1994)\n",
            "An Unforgettable Summer (1994)\n",
            "Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
            "My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\n",
            "Midnight Dancers (Sibak) (1994)\n",
            "Somebody to Love (1994)\n",
            "American Buffalo (1996)\n",
            "Kazaam (1996)\n",
            "Larger Than Life (1996)\n",
            "Two Deaths (1995)\n",
            "Stefano Quantestorie (1993)\n",
            "Crude Oasis, The (1995)\n",
            "Hedd Wyn (1992)\n",
            "Convent, The (Convento, O) (1995)\n",
            "Lotto Land (1995)\n",
            "Story of Xinghua, The (1993)\n",
            "Day the Sun Turned Cold, The (Tianguo niezi) (1994)\n",
            "Dingo (1992)\n",
            "Ballad of Narayama, The (Narayama Bushiko) (1958)\n",
            "Every Other Weekend (1990)\n",
            "Mille bolle blu (1993)\n",
            "Crows and Sparrows (1949)\n",
            "Lover's Knot (1996)\n",
            "Shadow of Angels (Schatten der Engel) (1976)\n",
            "1-900 (1994)\n",
            "Venice/Venice (1992)\n",
            "Infinity (1996)\n",
            "Ed's Next Move (1996)\n",
            "For the Moment (1994)\n",
            "The Deadly Cure (1996)\n",
            "Boys in Venice (1996)\n",
            "Sexual Life of the Belgians, The (1994)\n",
            "Search for One-eye Jimmy, The (1996)\n",
            "American Strays (1996)\n",
            "Leopard Son, The (1996)\n",
            "Bird of Prey (1996)\n",
            "Johnny 100 Pesos (1993)\n",
            "JLG/JLG - autoportrait de dcembre (1994)\n",
            "Faust (1994)\n",
            "Mina Tannenbaum (1994)\n",
            "Forbidden Christ, The (Cristo proibito, Il) (1950)\n",
            "I Can't Sleep (J'ai pas sommeil) (1994)\n",
            "Machine, The (1994)\n",
            "Stranger, The (1994)\n",
            "Good Morning (1971)\n",
            "Falling in Love Again (1980)\n",
            "Cement Garden, The (1993)\n",
            "Meet Wally Sparks (1997)\n",
            "Hotel de Love (1996)\n",
            "Rhyme & Reason (1997)\n",
            "Love and Other Catastrophes (1996)\n",
            "Hollow Reed (1996)\n",
            "Losing Chase (1996)\n",
            "Bonheur, Le (1965)\n",
            "Second Jungle Book: Mowgli & Baloo, The (1997)\n",
            "Squeeze (1996)\n",
            "Roseanna's Grave (For Roseanna) (1997)\n",
            "Tetsuo II: Body Hammer (1992)\n",
            "Fall (1997)\n",
            "Gabbeh (1996)\n",
            "Mondo (1996)\n",
            "Innocent Sleep, The (1995)\n",
            "For Ever Mozart (1996)\n",
            "Locusts, The (1997)\n",
            "Stag (1997)\n",
            "Swept from the Sea (1997)\n",
            "Hurricane Streets (1998)\n",
            "Stonewall (1995)\n",
            "Of Human Bondage (1934)\n",
            "Anna (1996)\n",
            "Stranger in the House (1997)\n",
            "Picture Bride (1995)\n",
            "M. Butterfly (1993)\n",
            "Ciao, Professore! (1993)\n",
            "Caro Diario (Dear Diary) (1994)\n",
            "Withnail and I (1987)\n",
            "Boy's Life 2 (1997)\n",
            "When Night Is Falling (1995)\n",
            "Specialist, The (1994)\n",
            "Gordy (1995)\n",
            "Swan Princess, The (1994)\n",
            "Harlem (1993)\n",
            "Barbarella (1968)\n",
            "Land Before Time III: The Time of the Great Giving (1995) (V)\n",
            "Street Fighter (1994)\n",
            "Coldblooded (1995)\n",
            "Next Karate Kid, The (1994)\n",
            "No Escape (1994)\n",
            "Turning, The (1992)\n",
            "Joy Luck Club, The (1993)\n",
            "Highlander III: The Sorcerer (1994)\n",
            "Gilligan's Island: The Movie (1998)\n",
            "My Crazy Life (Mi vida loca) (1993)\n",
            "Suture (1993)\n",
            "Walking Dead, The (1995)\n",
            "I Like It Like That (1994)\n",
            "I'll Do Anything (1994)\n",
            "Grace of My Heart (1996)\n",
            "Drunks (1995)\n",
            "SubUrbia (1997)\n",
            "Sliding Doors (1998)\n",
            "Ill Gotten Gains (1997)\n",
            "Legal Deceit (1997)\n",
            "Mighty, The (1998)\n",
            "Men of Means (1998)\n",
            "Shooting Fish (1997)\n",
            "Steal Big, Steal Little (1995)\n",
            "Mr. Jones (1993)\n",
            "House Party 3 (1994)\n",
            "Panther (1995)\n",
            "Jason's Lyric (1994)\n",
            "Above the Rim (1994)\n",
            "Moonlight and Valentino (1995)\n",
            "Scarlet Letter, The (1995)\n",
            "8 Seconds (1994)\n",
            "That Darn Cat! (1965)\n",
            "Ladybird Ladybird (1994)\n",
            "Bye Bye, Love (1995)\n",
            "Century (1993)\n",
            "My Favorite Season (1993)\n",
            "Pather Panchali (1955)\n",
            "Golden Earrings (1947)\n",
            "Foreign Correspondent (1940)\n",
            "Lady of Burlesque (1943)\n",
            "Angel on My Shoulder (1946)\n",
            "Angel and the Badman (1947)\n",
            "Outlaw, The (1943)\n",
            "Beat the Devil (1954)\n",
            "Love Is All There Is (1996)\n",
            "Damsel in Distress, A (1937)\n",
            "Madame Butterfly (1995)\n",
            "Sleepover (1995)\n",
            "Here Comes Cookie (1935)\n",
            "Thieves (Voleurs, Les) (1996)\n",
            "Boys, Les (1997)\n",
            "Stars Fell on Henrietta, The (1995)\n",
            "Last Summer in the Hamptons (1995)\n",
            "Margaret's Museum (1995)\n",
            "Saint of Fort Washington, The (1993)\n",
            "Cure, The (1995)\n",
            "Tom and Huck (1995)\n",
            "Gumby: The Movie (1995)\n",
            "Hideaway (1995)\n",
            "Visitors, The (Visiteurs, Les) (1993)\n",
            "Little Princess, The (1939)\n",
            "Nina Takes a Lover (1994)\n",
            "Bhaji on the Beach (1993)\n",
            "Raw Deal (1948)\n",
            "Nightwatch (1997)\n",
            "Dead Presidents (1995)\n",
            "Reckless (1995)\n",
            "Herbie Rides Again (1974)\n",
            "S.F.W. (1994)\n",
            "Gate of Heavenly Peace, The (1995)\n",
            "Man in the Iron Mask, The (1998)\n",
            "Jerky Boys, The (1994)\n",
            "Colonel Chabert, Le (1994)\n",
            "Girl in the Cadillac (1995)\n",
            "Even Cowgirls Get the Blues (1993)\n",
            "Germinal (1993)\n",
            "Chasers (1994)\n",
            "Fausto (1993)\n",
            "Tough and Deadly (1995)\n",
            "Window to Paris (1994)\n",
            "Modern Affair, A (1995)\n",
            "Mostro, Il (1994)\n",
            "Flirt (1995)\n",
            "Carpool (1996)\n",
            "Line King: Al Hirschfeld, The (1996)\n",
            "Farmer & Chase (1995)\n",
            "Grosse Fatigue (1994)\n",
            "Santa with Muscles (1996)\n",
            "Prisoner of the Mountains (Kavkazsky Plennik) (1996)\n",
            "Naked in New York (1994)\n",
            "Gold Diggers: The Secret of Bear Mountain (1995)\n",
            "Bewegte Mann, Der (1994)\n",
            "Killer: A Journal of Murder (1995)\n",
            "Nelly & Monsieur Arnaud (1995)\n",
            "Three Lives and Only One Death (1996)\n",
            "Babysitter, The (1995)\n",
            "Getting Even with Dad (1994)\n",
            "Mad Dog Time (1996)\n",
            "Children of the Revolution (1996)\n",
            "World of Apu, The (Apur Sansar) (1959)\n",
            "Sprung (1997)\n",
            "Dream With the Fishes (1997)\n",
            "Wings of Courage (1995)\n",
            "Wedding Gift, The (1994)\n",
            "Race the Sun (1996)\n",
            "Losing Isaiah (1995)\n",
            "New Jersey Drive (1995)\n",
            "Fear, The (1995)\n",
            "Mr. Wonderful (1993)\n",
            "Trial by Jury (1994)\n",
            "Good Man in Africa, A (1994)\n",
            "Kaspar Hauser (1993)\n",
            "Object of My Affection, The (1998)\n",
            "Witness (1985)\n",
            "Senseless (1998)\n",
            "Nowhere (1997)\n",
            "Underground (1995)\n",
            "Jefferson in Paris (1995)\n",
            "Far From Home: The Adventures of Yellow Dog (1995)\n",
            "Foreign Student (1994)\n",
            "I Don't Want to Talk About It (De eso no se habla) (1993)\n",
            "Twin Town (1997)\n",
            "Enfer, L' (1994)\n",
            "Aiqing wansui (1994)\n",
            "Cosi (1996)\n",
            "All Over Me (1997)\n",
            "Being Human (1993)\n",
            "Amazing Panda Adventure, The (1995)\n",
            "Beans of Egypt, Maine, The (1994)\n",
            "Scarlet Letter, The (1926)\n",
            "Johns (1996)\n",
            "It Takes Two (1995)\n",
            "Frankie Starlight (1995)\n",
            "Shadows (Cienie) (1988)\n",
            "Show, The (1995)\n",
            "The Courtyard (1995)\n",
            "Dream Man (1995)\n",
            "Destiny Turns on the Radio (1995)\n",
            "Glass Shield, The (1994)\n",
            "Hunted, The (1995)\n",
            "Underneath, The (1995)\n",
            "Safe Passage (1994)\n",
            "Secret Adventures of Tom Thumb, The (1993)\n",
            "Condition Red (1995)\n",
            "Yankee Zulu (1994)\n",
            "Aparajito (1956)\n",
            "Hostile Intentions (1994)\n",
            "Clean Slate (Coup de Torchon) (1981)\n",
            "Tigrero: A Film That Was Never Made (1994)\n",
            "Eye of Vichy, The (Oeil de Vichy, L') (1993)\n",
            "Promise, The (Versprechen, Das) (1994)\n",
            "To Cross the Rubicon (1991)\n",
            "Daens (1992)\n",
            "Man from Down Under, The (1943)\n",
            "Careful (1992)\n",
            "Vermont Is For Lovers (1992)\n",
            "Vie est belle, La (Life is Rosey) (1987)\n",
            "Quartier Mozart (1992)\n",
            "Touki Bouki (Journey of the Hyena) (1973)\n",
            "Wend Kuuni (God's Gift) (1982)\n",
            "Spirits of the Dead (Tre passi nel delirio) (1968)\n",
            "Pharaoh's Army (1995)\n",
            "I, Worst of All (Yo, la peor de todas) (1990)\n",
            "Hungarian Fairy Tale, A (1987)\n",
            "Death in the Garden (Mort en ce jardin, La) (1956)\n",
            "Collectionneuse, La (1967)\n",
            "Baton Rouge (1988)\n",
            "Liebelei (1933)\n",
            "Woman in Question, The (1950)\n",
            "T-Men (1947)\n",
            "Invitation, The (Zaproszenie) (1986)\n",
            "Symphonie pastorale, La (1946)\n",
            "American Dream (1990)\n",
            "Lashou shentan (1992)\n",
            "Terror in a Texas Town (1958)\n",
            "Salut cousin! (1996)\n",
            "Schizopolis (1996)\n",
            "To Have, or Not (1995)\n",
            "Duoluo tianshi (1995)\n",
            "Magic Hour, The (1998)\n",
            "Death in Brunswick (1991)\n",
            "Everest (1998)\n",
            "Shopping (1994)\n",
            "Nemesis 2: Nebula (1995)\n",
            "Romper Stomper (1992)\n",
            "City of Industry (1997)\n",
            "Someone Else's America (1995)\n",
            "Guantanamera (1994)\n",
            "Office Killer (1997)\n",
            "Price Above Rubies, A (1998)\n",
            "Angela (1995)\n",
            "He Walked by Night (1948)\n",
            "Love Serenade (1996)\n",
            "Buddy (1997)\n",
            "B*A*P*S (1997)\n",
            "Truth or Consequences, N.M. (1997)\n",
            "Intimate Relations (1996)\n",
            "Leading Man, The (1996)\n",
            "Tokyo Fist (1995)\n",
            "Reluctant Debutante, The (1958)\n",
            "Warriors of Virtue (1997)\n",
            "Desert Winds (1995)\n",
            "King of New York (1990)\n",
            "All Things Fair (1996)\n",
            "Sixth Man, The (1997)\n",
            "Butterfly Kiss (1995)\n",
            "Paris, France (1993)\n",
            "Crmonie, La (1995)\n",
            "Hush (1998)\n",
            "Nobody Loves Me (Keiner liebt mich) (1994)\n",
            "Wife, The (1995)\n",
            "Lamerica (1994)\n",
            "Nico Icon (1995)\n",
            "Silence of the Palace, The (Saimt el Qusur) (1994)\n",
            "Slingshot, The (1993)\n",
            "Land and Freedom (Tierra y libertad) (1995)\n",
            " kldum klaka (Cold Fever) (1994)\n",
            "Etz Hadomim Tafus (Under the Domin Tree) (1994)\n",
            "Two Friends (1986) \n",
            "Brothers in Trouble (1995)\n",
            "Girls Town (1996)\n",
            "Normal Life (1996)\n",
            "Bitter Sugar (Azucar Amargo) (1996)\n",
            "Eighth Day, The (1996)\n",
            "Dadetown (1995)\n",
            "Some Mother's Son (1996)\n",
            "Angel Baby (1995)\n",
            "Sudden Manhattan (1996)\n",
            "Butcher Boy, The (1998)\n",
            "Men With Guns (1997)\n",
            "Hana-bi (1997)\n",
            "Niagara, Niagara (1997)\n",
            "Big One, The (1997)\n",
            "Spanish Prisoner, The (1997)\n",
            "Temptress Moon (Feng Yue) (1996)\n",
            "Entertaining Angels: The Dorothy Day Story (1996)\n",
            "Favor, The (1994)\n",
            "Little City (1998)\n",
            "Target (1995)\n",
            "Getting Away With Murder (1996)\n",
            "Small Faces (1995)\n",
            "New Age, The (1994)\n",
            "Rough Magic (1995)\n",
            "Nothing Personal (1995)\n",
            "8 Heads in a Duffel Bag (1997)\n",
            "Brother's Kiss, A (1997)\n",
            "Ripe (1996)\n",
            "Next Step, The (1995)\n",
            "Wedding Bell Blues (1996)\n",
            "MURDER and murder (1996)\n",
            "Tainted (1998)\n",
            "Further Gesture, A (1996)\n",
            "Kika (1993)\n",
            "Mirage (1995)\n",
            "Mamma Roma (1962)\n",
            "Sunchaser, The (1996)\n",
            "War at Home, The (1996)\n",
            "Sweet Nothing (1995)\n",
            "Mat' i syn (1997)\n",
            "B. Monkey (1998)\n",
            "You So Crazy (1994)\n",
            "Scream of Stone (Schrei aus Stein) (1991)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GYjcB7R7cV1"
      },
      "source": [
        "def similar_movie(rating_df, num_users, num_items, moviesDF, movie_name, top_k = 5):\n",
        "  \n",
        "  # getting the item item similarity\n",
        "  user_item_matrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "  item_user_matrix = user_item_matrix.transpose()\n",
        "  item_item_similarity = SimBasedRecSys.cosine(item_user_matrix)\n",
        "\n",
        "  # getting the argument of the movie\n",
        "  item_id = moviesDF[moviesDF['movieTitle']== movie_name]['movieID'].values[0]\n",
        "\n",
        "  # getting to similar movies with the item_id\n",
        "  top_similar_movies_id =  np.argsort(item_item_similarity[item_id-1])[::-1][1:top_k+1]\n",
        "\n",
        "  print('Searched movie =', movie_name, '\\n')\n",
        "  print('---------- top', top_k, 'movies ----------\\n')\n",
        "  \n",
        "  for i in top_similar_movies_id:\n",
        "    top_movies_name = moviesDF[moviesDF['movieID'] == i+1]['movieTitle'].values[0]\n",
        "    print(top_movies_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pnrHr1c7cY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1380a8e-7433-422f-e181-de568d38c0ee"
      },
      "source": [
        "similar_movie(rating_df, num_users, num_items, moviesDF, movie_name = 'Hush (1998)', top_k = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searched movie = Hush (1998) \n",
            "\n",
            "---------- top 5 movies ----------\n",
            "\n",
            "Nightwatch (1997)\n",
            "Wild Things (1998)\n",
            "City of Angels (1998)\n",
            "Man in the Iron Mask, The (1998)\n",
            "Star Maps (1997)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF60aIk17ch4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9dcf7d-ef27-4c2f-f927-c0220def0cd7"
      },
      "source": [
        "similar_movie(rating_df, num_users, num_items, moviesDF, movie_name = 'No Escape (1994)', top_k = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searched movie = No Escape (1994) \n",
            "\n",
            "---------- top 5 movies ----------\n",
            "\n",
            "Gate of Heavenly Peace, The (1995)\n",
            "Nemesis 2: Nebula (1995)\n",
            "Shopping (1994)\n",
            "Body Parts (1991)\n",
            "Surviving the Game (1994)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCYl7fDH7cet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0e1216-5054-41fa-940e-88e95f0cf9f8"
      },
      "source": [
        "similar_movie(rating_df, num_users, num_items, moviesDF, movie_name = 'Angel Baby (1995)', top_k = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searched movie = Angel Baby (1995) \n",
            "\n",
            "---------- top 5 movies ----------\n",
            "\n",
            "Love Serenade (1996)\n",
            "Mondo (1996)\n",
            "Designated Mourner, The (1997)\n",
            "Silence of the Palace, The (Saimt el Qusur) (1994)\n",
            "Normal Life (1996)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnRDOuH4zdvF"
      },
      "source": [
        "### (b)\n",
        "\n",
        "**---- Note ----**\n",
        "\n",
        "The similar movies retreived can be justified even though indirectly they are influenced by the user because a users preferance can depict interest or popularity of the movie of that genre or in that year. The output of the above searches are of similar genre and even the similar time period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiSiG2UrzdvK"
      },
      "source": [
        "## 7. Testing with different user types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH63iq22zdvK"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3_5JH6Qe_o"
      },
      "source": [
        "threshold = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeUK2ZR5zdvM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "c604a1b7-8c5c-4e84-eb60-feae5522bd60"
      },
      "source": [
        "num_user_rating_df = rating_df.groupby('userID').size().to_frame(name='len_ratings').sort_values(by=['len_ratings'], ascending=False)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Dist. of number of ratings per user', fontsize = 15)\n",
        "plt.xlabel('bins', fontsize = 12)\n",
        "plt.ylabel('frequency', fontsize = 12)\n",
        "plt.hist(num_user_rating_df.len_ratings.values, bins='auto', edgecolor='black', linewidth=1.0)\n",
        "\n",
        "plt.axhline(y=threshold, color = 'black')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f048ebc9be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFSCAYAAAC37XiSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxdZX3v8c9XwlRAEIkYCRhQ6tiKmFK42opSBSkV6VUKthUtNraC1atW0PYqbaW3tA51Ki0WBFsHnEEcEcGpCoZBRtEIwSQGiDIIKijwu3+sdWCzOSfZOcPeK9mf9+u1X2etZ03Pes45Od88zxpSVUiSJKkbHjTqCkiSJOk+hjNJkqQOMZxJkiR1iOFMkiSpQwxnkiRJHWI4kyRJ6hDDmTSFJMclqfZzT5Kbk3w7yfFJHt637qJ2vYMG3Pdm7f73mJva33ucg5NcleSXSZbP5bFmqm2PH4+6HlMZRlsmWZLkeZOUL0/ylrk4pqTumTfqCkgddytwQDu9LbAn8JfAkiQHVNWF7bLVwD7Adwfc72bAm4DlwCWzVtseSTYB3g98Dvhz4GdzcZxxMMS2XAJcDnyqr/wQ4CdzdExJHWM4k9burqr6Vs/8F5KcCHwV+HCSx1bV3VV1J/CtyXcxMguABwMfrKqvj7oyo9SGq02q6pfT3MW02zLJllX1i2keF4Cqungm229IZqO95kJX66WNk8Oa0nqqqluA1wGPBp4Fkw9rJnlukguT/KwdEj0/ydPbxbe1X9/XM3S6aH3qkeTQJJcluTPJina4dV677MXAinbVM9r9HzfFfvZtl++b5KNJbk9yTZKX9613XpKPTbHtE/va4bAk70vy0yQrk/xJu/x1SX6UZE2SE5I84N+gJE9NclGSO5JckuRpk6zz0iRXtOd+XZLX9S0/NcnSJM9LcgVwB/DbQ2zL/ZOcmeR24N3tste0w+K3JrkhyaeTPLq3fYGnAEf0/Ey8uF12v2HNnvN7VpJL25+xryd5Ql99HpLkw+3yHyU5Jslbeodlk2yX5D/b5Xck+WGS907VVhN1TfKxdhh2eZJfJPlMkp361tsiyT+3bXpnku8kObBvneVJ3prk/yZZCfx0LcetJEf3ld1vOHyQ80nyxLa+t7Wfj6bnUoW1fR+lYTCcSdNzHnAXsPdkC5M8CvgY8GXgD4A/Bs4Ctm9XeWb79c00w6H70AyNDiTJs4HTgYuAg4F3Aa/lvj8gnwH+sJ1+bbv//1zHbt8LfIdmCO084D1J9hq0Tn1OoDmf/w18DTgtyVuBvYA/A/6VJuAe2rfdrwH/Dfw78ALgFuBzfX84/xo4kWbo76B2+h/6/2gDi4B/Bv4f8Bzg2skqOkdteTJNWz63nQZY2O7zYJqh0U2A/0mybbv85TTD4p/lvp+Jz6zlGLsA/wIcDxwOPAw4PUl61jmV5j8Qr6QZMn028Ed9+3kb8DTg/wD7A28ABnmv3z7AK4BXA0cCv8kDh2M/BrwY+Eea34NvA2fmgddavhB4Ok0b9Ndvfa31fNpA/A1gC+BP2vo9Afh0X9vB5N9Hae5VlR8/fib5AMcBP17L8tXAie30Ipo/AAe1888HfrKWbbdu13/xNOv2LeDcvrLXAXcDCyer01r2tW+73t/3lG0KrAH+qafsPOBjU2z7xL5jvq9nnQcDvwK+TzO0OFF+AXB6X3sX8MK+drppoh7tvm4H3tRXj78Hrp/YP00oKWCPEbXl29ex3ibAljQ9qC/qKV8KnDrJ+suBt/TMn0rzn4Pde8qe1x77se38E9v5F/SssyXwY2B5T9nlwCvW8+fvvPZ7uktP2VPb4x3Qzu/Xzj+9b9uvAh/tO7fVwBYDHLeAo/vKjqPn93Rd5wP8F3A1sFlP2e7t9/v31+f76MfPXH3sOZOmr/9/2b0uA7ZNclqSZyfZatYO2lw/tSfw0b5Fp9P0hu8zzV1/cWKiqibC1MJp7uucnn39lCbofaWq7u5ZZxmwU/+GwCd7tr0dOJumxw2ac9sK+GiSeRMfmh7KHfvqu6qq1nqzxRy25QN6vJLsneTsJD+hCVY/pwmfvz7NYyyvqu/3zF/Zfp1og8Xt109PrFDNNVNf6tvPJcBfJ3l5kvWpy0VV9cOefX8DuJH7vle/RxOYv9H3vTqnp24TzqmqO9bj2GuzrvP5PZqfsXt66nQtTUjsr9faei6lOWM4k6YhyRbAQ4EbJlteVVfTDF/tRjNM9eMkH0wyfxYOvwNNz1b/sSfmt2d6bumb/yXN0M9s7WuQ/d9eD7zo+kaaC/KhOXeAK2h6biY+57blO/dsN+n3ps9cteX99pdkF5rwG+BlNL1Mv0VzbrPZxvTs7+HAbZOEnjV980fTDEe+Ebg6yfeTHDbA8W+coqz3e/Vw7v99+hVNT9fOfdsN8r0a1LrOZwfgmEnqtdsc10samHdrStPzDJrfn29OtUJVfQb4THtN0e/TXGf1LmCQP3xr82OaPyYP6yvfsf160wz3P5U7aB4B0ushs3yMrfPAu+Iexn3X402c20FM/ofz6p7pQa6bmqu27D/2ATTX0x1cVT8DaHtsphv+BnE9sE2SLfoC2v3+g1DNDS5/BfxVkt+kGdL9QJJLq+pKptbfZhNlvd+rVTTDresyyPcK4E7W8TM4wPncRNNzNtl1g/3P2Ru0XtKssudMWk9JtqO54H0ZDxwieoCqurWqPkjzB+HxbXF/L8fA2qHBC2kumO91KHAPawmMM7QSeGxf2bPn4DiHTEwk2ZrmgvYL2qJvAr8AHlFVSyf53DbJ/qY0xLbcst3fXX3H6P8P8kx6K/stbb8+d6IgyZa0dxhPpqouBf6a5m9D//e6355tj+DEvp9KE84mvlfn0PSc3T7Z92q9z6axEnhczzEfRHNt26SmOJ9zaG4AuHCSei2fZr2kWWXPmbR285JM3JG5Dc2jDv6SphfkgL5rqO6V5GU01yt9HvgRzQXHL6B5kClV9csk1wKHJrmcplfq0rZ8Gc31WUeupV5vonnm2vuADwO/AfwD8N6qWjmjM57aJ4Ejk7yd5lqcZ3DfA3pnyy+A49tQ9iOauyM3A94BTa9ImsdYvCPJI2kuLn8QzXVbz6iqQybd69oNoy2/THMTwPuSnEwTDl7LA4cmvwvsn2R/mofOXltV03r4bFVdnuTTwIlJtqHpSXs1zbVu90ysl+TrNN/by2l6iiYesnvBA3Z6f2toeobfRBMoT6C5Du3z7fKzgS8AZyc5gWYo+sHAHjQX/79+Gqf1SeCoJBcD1wAvbfd5rwHO57h2+jNJTqHpLduJJrSeWlXnTaNe0qwynElrty1N70nRPH9pGc2jHt5VVdevZbtLaXos3kYzdLWa5lEVb+xZ5y+At9D0vm0O7EpzUfI8mj/kU6qqL7bX0fwtzWM6bgTeShM05kRVfSbJG2ged/BS4AyaRzScMYuH+TnwIprh38fRhJUDq+rex4xU1T8n+RHNoxJeQxNsv0dzEf96G0ZbVtVlaZ5ZdhxNz+B3aMJ6f53fTPOIjI/QhI6X0NyZOV0vpnnUyDtp7nJ9D02o+a2edb7ZrreI5o7Fi4HnDBBM/4fmZ/dfaYZKz6N5XAcAVVVJ/pDmURavojmvm2gu2H/XNM/n72h6595M08v4bprQd9Sg51NV32v/w/Vm4CSaXs1VND1qy6ZZL2lWpcohdUkaB+11bpcD51fVETPYz3k0j694/mzVTdJ97DmTpI1UkhcAj6B5tMuDaYb4dqfpnZTUUYYzSdp4/YxmaPTRNEPllwF/UFXrup5M0gg5rClJktQhPkpDkiSpQwxnkiRJHbLRXHO2ww471KJFi0ZdDUmSpHW68MILf1xVk77Sb6MJZ4sWLWLp0uk+dFqSJGl4klw31TKHNSVJkjrEcCZJktQhhjNJkqQOMZxJkiR1iOFMkiSpQwxnkiRJHWI4kyRJ6hDDmSRJUocYziRJkjrEcCZJktQhhjNJkqQOMZytpwULdyHJtD8LFu4y6lOQJEkdttG8+HxYrl+1gkcec9a0t7/uhINmsTaSJGljY8+ZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4xnEmSJHWI4UySJKlDDGeSJEkdYjiTJEnqEMOZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4xnEmSJHWI4UySJKlDDGeSJEkdYjiTJEnqEMOZJElShxjOJEmSOmQo4SzJFkkuSPKdJFck+bu2fNck5ydZluT0JJu15Zu388va5YuGUU9JkqRRG1bP2Z3AM6vqScAewAFJ9gZOAN5eVY8GbgaObNc/Eri5LX97u54kSdJGbyjhrBq3t7Obtp8Cngl8rC0/DXheO31wO0+7fL8kGUZdJUmSRmlo15wl2STJJcCNwNnAD4BbququdpWVwE7t9E7ACoB2+a3AQ4dVV0mSpFEZWjirqrurag9gIbAX8NiZ7jPJkiRLkyxds2bNjOsoSZI0akO/W7OqbgHOBfYBtksyr120EFjVTq8CdgZol28L/GSSfZ1UVYuravH8+fPnvO6SJElzbVh3a85Psl07vSXwLOAqmpD2/Ha1I4Az2ukz23na5V+uqhpGXSVJkkZp3rpXmRULgNOSbEITCD9SVWcluRL4cJI3AxcDJ7frnwz8V5JlwE3AYUOqpyRJ0kgNJZxV1aXAkycpv4bm+rP+8juAFwyhapIkSZ3iGwIkSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR0ylHCWZOck5ya5MskVSV7Zlh+XZFWSS9rPgT3bvD7JsiRXJ9l/GPWUJEkatXlDOs5dwGuq6qIk2wAXJjm7Xfb2qnpL78pJHg8cBjwBeATwpSS/XlV3D6m+kiRJIzGUnrOqWl1VF7XTtwFXATutZZODgQ9X1Z1VdS2wDNhr7msqSZI0WkO/5izJIuDJwPlt0dFJLk1ySpKHtGU7ASt6NlvJ2sOcJEnSRmGo4SzJ1sDHgVdV1U+BE4FHAXsAq4G3ruf+liRZmmTpmjVrZr2+kiRJwza0cJZkU5pg9oGq+gRAVd1QVXdX1T3Ae7lv6HIVsHPP5gvbsvupqpOqanFVLZ4/f/7cnoAkSdIQDOtuzQAnA1dV1dt6yhf0rHYIcHk7fSZwWJLNk+wK7A5cMIy6SpIkjdKw7tZ8KvCnwGVJLmnL3gAcnmQPoIDlwMsAquqKJB8BrqS50/Mo79SUJEnjYCjhrKq+DmSSRZ9dyzbHA8fPWaUkSZI6yDcESJIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR0yUDhL8skkz0uy6VxXSJIkaZwN2nP2NeCNwPVJTkzyv+awTpIkSWNroHBWVW+rqj2B3wVuAT6U5PtJ3pjkUXNaQ0mSpDGyXtecVdUVVfV64E+AnwNvAi5K8qUkT5qLCkqSJI2TgcNZksck+YckPwBOAk4HFgE7Ap8FPrWWbXdOcm6SK5NckeSVbfn2Sc5ue+HOTvKQtjxJ3plkWZJLk+w5g3OUJEnaYAx6Q8BS4BvA9sALq+pxVfWPVbWiqu6oqretYxd3Aa+pqscDewNHJXk8cCxwTlXtDpzTzgM8B9i9/SwBTlzfE5MkSdoQzRtwvX8CzqyqX061QlXtupZlq4HV7fRtSa4CdgIOBvZtVzsNOA84pi1/f1UV8K0k2yVZ0O5HkiRpozXosOZPaYYw79UOcz5rfQ+YZBHwZOB8YMeewHU9zRApNMFtRc9mK9uy/n0tSbI0ydI1a9asb1UkSZI6Z9Bw9h7gtr6y29rygSXZGvg48Kqq+mnvsraXrNZnf1V1UlUtrqrF8+fPX59NJUmSOmnQcPawSYYUVwMPH/RA7QNsPw58oKo+0RbfkGRBu3wBcGNbvgrYuWfzhW2ZJEnSRm3QcHZNkmf2le0LXDvIxkkCnAxc1XfzwJnAEe30EcAZPeUvau/a3Bu41evNJEnSOBj0hoDjgE8kORn4AfAo4CXtZxBPBf4UuCzJJW3ZG2huNPhIkiOB64BD22WfBQ4EltE8T23Q40iSJG3QBgpnVXVGkmcDfwb8Ps3F+vtX1bcH3P7rQKZYvN8k6xdw1CD7liRJ2pgM2nNGVV0AXDCHdZEkSRp7A4WzJJsBLwb2ALbuXVZVL5r9akmSJI2nQXvOTgOeBHwauGHuqiNJkjTeBg1nBwC7VtUtc1kZSZKkcTfoozR+CGw+lxWRJEnS4D1n7wfOSPIO+oY1q+rLs14rSZKkMTVoODu6/fqPfeUF7DZ71ZEkSRpvgz7nbNe5rogkSZIGv+aMJJsm+Z0kf9TOb5Vkq7mrmiRJ0vgZKJwl+Q3ge8B7ad6RCfB04JQ5qpckSdJYGrTn7ETgjVX1WOBXbdlXgKfNSa0kSZLG1KDh7AnAf7fTBVBVPwO2nItKSZIkjatBw9ly4Cm9BUn2ApbNdoUkSZLG2aCP0vi/wGeS/DuwWZLXA38B/Pmc1UySJGkMDdRzVlVn0bzCaT7NtWaPBP6wqr44h3WTJEkaO4P2nFFVFwMvn8O6SJIkjb2BwlmSv59qWVW9cfaqI0mSNN4G7TnbuW/+4TTPOfvk7FZHkiRpvA36+qaX9JclOQA4fNZrJEmSNMYGfn3TJL4IPG+2KiJJkqTBrznbra/o14AXAitmvUaSJEljbNBrzpbRvBkg7fzPgYuBI+aiUpIkSeNq0GvOZjL8KUmSpAEZuiRJkjpk0GvOVtC+8HxtqmqXGddIkiRpjA16zdk7aK4veydwHc3rm44G3g8snZuqSZIkjZ9Bw9mLgf2ratVEQZLPAZ+vqrfORcUkSZLG0aDXnD0CuL2v7HZgp9mtjiRJ0ngbNJydCZyZ5FlJHpfk2TSvbjpz7qomSZI0fgYNZ38BfBP4d+Ai4ETg/LZckiRJs2SgcFZVd1TVsVX1qKrasv16bFX9YpDtk5yS5MYkl/eUHZdkVZJL2s+BPcten2RZkquT7L/+pyVJkrRhGvg5Z+2Q5slJPt3OL07yzAE3PxU4YJLyt1fVHu3ns+1+Hw8cBjyh3ebfkmwyaD0lSZI2ZAOFsySvoBnK/D7wu23xL4A3D7J9VX0VuGnAOh0MfLiq7qyqa2leHbXXgNt23yabkmTanwULfZScJEkbs0EfpfEqYL+qWp7kmLbsu8BjZnj8o5O8iOZZaa+pqptp7gD9Vs86K5nirtAkS4AlALvssoGElrt/xSOPOWvam193wkGzWBlJktQ1gw5rbgOsaKcn3hSwKfDLGRz7ROBRwB7AamC9n5dWVSdV1eKqWjx//vwZVEWSJKkbBg1nXwWO7Sv7K+Dc6R64qm6oqrur6h7gvdw3dLkK2Lln1YVtmSRJ0kZv0HD2CuCQJMuBbZJcDRwKvHq6B06yoGf2EGDiTs4zgcOSbJ5kV2B34ILpHkeSJGlDss5rzpI8CHgc8DvAb9C8V3MFcEHb67VOST4E7AvskGQl8CZg3yR70AyTLgdeBlBVVyT5CHAlcBdwVFXdvX6nJUmStGFaZzirqnuSnFFV29D0YK13L1ZVHT5J8clrWf944Pj1PY4kSdKGbuBrzpLsPac1kSRJ0sCP0rgO+FySM2iGNCfu2KSq3jgXFZMkSRpHU/acJTm6Z3Zb4FM0oWwhzd2UEx9JkiTNkrX1nB0PvLud/oOqevAQ6iNJkjTW1hbOrknyVuAKYNMkLwHSv1JVnTJXlZMkSRo3awtnfwS8Djic5m0AL5pknQIMZ5IkSbNkynBWVd8DXgqQ5Jyq2m9otZIkSRpTAz1Kw2AmSZI0HIM+50ySJElDYDiTJEnqEMOZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4xnEmSJHWI4UySJKlDDGeSJEkdYjiTJEnqEMOZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4xnEmSJHWI4UySJKlDDGeSJEkdYjiTJEnqEMOZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4ZSjhLckqSG5Nc3lO2fZKzk3y//fqQtjxJ3plkWZJLk+w5jDpKkiR1wbB6zk4FDugrOxY4p6p2B85p5wGeA+zefpYAJw6pjpIkSSM3lHBWVV8FbuorPhg4rZ0+DXheT/n7q/EtYLskC4ZRT0mSpFEb5TVnO1bV6nb6emDHdnonYEXPeivbMkmSpI1eJ24IqKoCan23S7IkydIkS9esWTMHNZMkSRquUYazGyaGK9uvN7blq4Cde9Zb2JY9QFWdVFWLq2rx/Pnz57SykiRJwzDKcHYmcEQ7fQRwRk/5i9q7NvcGbu0Z/pQkSdqozRvGQZJ8CNgX2CHJSuBNwD8BH0lyJHAdcGi7+meBA4FlwM+BlwyjjpIkSV0wlHBWVYdPsWi/SdYt4Ki5rZEkSVI3deKGAEmSJDUMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYazDc0mm5JkRp8FC3cZ9VlIkqQpzBt1BbSe7v4VjzzmrBnt4roTDpqlykiSpNlmz5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcjaMZ3vHp3Z6SJM0d79YcRzO849O7PSVJmjv2nEmSJHWI4UySJKlDDGeSJEkdYjiTJEnqEMOZJElShxjOJEmSOsRwJkmS1CGGM0mSpA4Z+UNokywHbgPuBu6qqsVJtgdOBxYBy4FDq+rmUdVRkiRpWLrSc/aMqtqjqha388cC51TV7sA57by6wtc/SZI0Z0beczaFg4F92+nTgPOAY0ZVGfWZ6euf3nIISWZUhYfvtDOrV/5wRvuQJKmLUlWjrUByLXAzUMB/VNVJSW6pqu3a5QFunpifyjbbbFNPecpT5ry+X/nKV9h85ydOe/s7V1w+0u27UIfZOoenP/3pM9qHJEmj8pWvfOXCnhHD++lCz9nTqmpVkocBZyf5bu/CqqokkybIJEuAJQCbb7753NdUkiRpjo2856xXkuOA24E/B/atqtVJFgDnVdVj1rbt4sWLa+nSpcOo48yG9E44aKTbd6EOs3UOXfrZlSRpfSSZsudspDcEJNkqyTYT08CzgcuBM4Ej2tWOAM4YTQ0lSZKGa9TDmjsCn2wvDp8HfLCqPp/k28BHkhwJXAccOsI6SpIkDc1Iw1lVXQM8aZLynwD7Db9GkiRJo9WV55xJkiQJw5kkSVKnGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTBumTTYlybQ/8zbfckbbL1i4y6hbQJK0kRr1Q2il6bn7VyN/BZUkSXPBnjNJkqQOMZxJkiR1iOFMkiSpQwxn0nTM8IYEbyqQJE3FGwKk6ZjhDQngTQWSpMnZcyZJktQhhjNJkqQOMZxJozLD69a8Zk2SNk5ecyaNyiw8SFeStPGx50ySJKlDDGeSJEkdYjiTJEnqEMOZNMYWLNzFmxIkqWO8IUDaULV3e86UNyVIUrcYzqQNlW8pkKSNksOakiRJHWI4kzR9PkhXkmadw5qSps8H6UrSrLPnTJIkqUMMZ5JGZ4bDog6NStoYOawpaXRm447Ttxwyo0eKbLLZFtz9yzumvf3Dd9qZ1St/OO3tJamf4UzShm0WrnvzujlJXdLpYc0kByS5OsmyJMeOuj6S9AAOzUqaZZ3tOUuyCfAe4FnASuDbSc6sqitHWzNJ6tGBodkuDK0uWLgL169aMe3tu3AOUld0NpwBewHLquoagCQfBg4GDGeSNi4bwSNJrl+1YoM/B6krujysuRPQ+9+wlW2ZJKnXDIdW522+5YyHZkd9DrNxHhvD8PKChbuMvA1GXYeZHr8LPwupqpFWYCpJng8cUFUvbef/FPjtqjq6Z50lwJJ29jHA1QPufgfgx7NY3Y2JbTM122Zqts3kbJep2TZTs22mtjG1zSOrav5kC7o8rLkK2LlnfmFbdq+qOgk4aX13nGRpVS2eWfU2TrbN1Gybqdk2k7NdpmbbTM22mdq4tE2XhzW/DeyeZNckmwGHAWeOuE6SJElzqrM9Z1V1V5KjgS8AmwCnVNUVI66WJEnSnOpsOAOoqs8Cn52DXa/3UOgYsW2mZttMzbaZnO0yNdtmarbN1MaibTp7Q4AkSdI46vI1Z5IkSWNn7MJZxvyVUElOSXJjkst7yrZPcnaS77dfH9KWJ8k727a6NMmeo6v53Eqyc5Jzk1yZ5Iokr2zLbZtkiyQXJPlO2zZ/15bvmuT8tg1Ob2/cIcnm7fyydvmiUdZ/riXZJMnFSc5q522XVpLlSS5LckmSpW2Zv1PJdkk+luS7Sa5Kso/tAkke0/6sTHx+muRV49g2YxXOct8roZ4DPB44PMnjR1uroTsVOKCv7FjgnKraHTinnYemnXZvP0uAE4dUx1G4C3hNVT0e2Bs4qv3ZsG3gTuCZVfUkYA/ggCR7AycAb6+qRwM3A0e26x8J3NyWv71db2P2SuCqnnnb5f6eUVV79Dz+wN8peAfw+ap6LPAkmp+fsW+Xqrq6/VnZA3gK8HPgk4xj21TV2HyAfYAv9My/Hnj9qOs1gnZYBFzeM381sKCdXgBc3U7/B3D4ZOtt7B/gDJr3uto292+XXwMuAn6b5kGQ89rye3+3aO6w3qednteul1HXfY7aYyHNH4tnAmcBsV3u1z7LgR36ysb6dwrYFri2/3s/7u0ySTs9G/jGuLbNWPWc4SuhprJjVa1up68Hdmynx7K92uGmJwPnY9sA9w7dXQLcCJwN/AC4paruaiEUwOAAAAP6SURBVFfpPf9726Zdfivw0OHWeGj+FXgdcE87/1Bsl14FfDHJhWne6AL+Tu0KrAHe1w6H/2eSrbBd+h0GfKidHru2GbdwpnWo5r8fY3sLb5KtgY8Dr6qqn/YuG+e2qaq7qxlqWAjsBTx2xFUauSQHATdW1YWjrkuHPa2q9qQZfjoqye/2LhzT36l5wJ7AiVX1ZOBn3DdMB4xtu9yrvU7zucBH+5eNS9uMWzhb5yuhxtQNSRYAtF9vbMvHqr2SbEoTzD5QVZ9oi22bHlV1C3AuzXDddkkmnpXYe/73tk27fFvgJ0Ou6jA8FXhukuXAh2mGNt+B7XKvqlrVfr2R5tqhvfB3aiWwsqrOb+c/RhPWxr1dej0HuKiqbmjnx65txi2c+UqoyZ0JHNFOH0FzvdVE+YvaO2L2Bm7t6VreqCQJcDJwVVW9rWeRbZPMT7JdO70lzbV4V9GEtOe3q/W3zUSbPR/4cvu/3Y1KVb2+qhZW1SKaf0u+XFV/zJi3y4QkWyXZZmKa5hqiyxnz36mquh5YkeQxbdF+wJWMebv0OZz7hjRhHNtm1Be9DfsDHAh8j+aamb8ZdX1GcP4fAlYDv6L5H9yRNNe9nAN8H/gSsH27bmjubv0BcBmweNT1n8N2eRpNV/mlwCXt50DbpgB+E7i4bZvLgTe25bsBFwDLaIYfNm/Lt2jnl7XLdxv1OQyhjfYFzrJd7tcmuwHfaT9XTPx76+9UQXPX89L2d+pTwENsl3vbZiuaHuVte8rGrm18Q4AkSVKHjNuwpiRJUqcZziRJkjrEcCZJktQhhjNJkqQOMZxJkiR1iOFM0thJsjzJ701S/jtJrh5FnSRpwrx1ryJJ46GqvgY8Zp0rStIcsudMkiSpQwxnksbVbyW5MsnNSd6XZIsk+yZZObFCO/z52iSXJrk1yelJtmiX7ZDkrCS3JLkpydeS+G+qpBnzHxJJ4+qPgf2BRwG/DvztFOsdChwA7ErzKqsXt+WvoXkF2nxgR+ANNK8Ak6QZMZxJGlfvrqoVVXUTcDzNy5Yn886q+lG73qdp3osIzftpFwCPrKpfVdXXyvfhSZoFhjNJ42pFz/R1wCOmWO/6numfA1u30/9C8xLzLya5Jsmxs19FSePIcCZpXO3cM70L8KP12biqbquq11TVbsBzgVcn2W82KyhpPBnOJI2ro5IsTLI98DfA6euzcZKDkjw6SYBbgbuBe+agnpLGjOFM0rj6IPBF4BrgB8Cb13P73YEvAbcD3wT+rarOndUaShpL8fpVSZKk7rDnTJIkqUMMZ5IkSR1iOJMkSeoQw5kkSVKHGM4kSZI6xHAmSZLUIYYzSZKkDjGcSZIkdYjhTJIkqUP+P+HAmnxr/ab5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFwx-6nDRobk"
      },
      "source": [
        "# choosing userid around threshold\n",
        "userid_above_thresh = num_user_rating_df[num_user_rating_df.len_ratings >= threshold].index.values\n",
        "userid_below_thresh = num_user_rating_df[num_user_rating_df.len_ratings < threshold].index.values\n",
        "\n",
        "# selecting dataframe from above and below\n",
        "rating_df_train_above_thresh = rating_df_train[rating_df_train.userID.isin(userid_above_thresh)]\n",
        "rating_df_train_below_thresh = rating_df_train[rating_df_train.userID.isin(userid_below_thresh)]\n",
        "\n",
        "rating_df_test_above_thresh = rating_df_test[rating_df_test.userID.isin(userid_above_thresh)]\n",
        "rating_df_test_below_thresh = rating_df_test[rating_df_test.userID.isin(userid_below_thresh)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQud9XsRo0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57b81f7-88e9-4d2a-b976-3a19321fe5c6"
      },
      "source": [
        "# model generation\n",
        "user_user_sim_above_thresh_recsys = SimBasedRecSys('user','cosine')\n",
        "user_user_sim_above_thresh_recsys.predict_all(rating_df_train_above_thresh, num_users, num_items)\n",
        "user_user_sim_above_thresh_recsys_testdf = user_user_sim_above_thresh_recsys.evaluate_test(rating_df_test_above_thresh)\n",
        "\n",
        "user_user_sim_below_thresh_recsys = SimBasedRecSys('user','cosine')\n",
        "user_user_sim_below_thresh_recsys.predict_all(rating_df_train_below_thresh, num_users, num_items)\n",
        "user_user_sim_below_thresh_recsys_testdf = user_user_sim_below_thresh_recsys.evaluate_test(rating_df_test_below_thresh)\n",
        "\n",
        "item_item_sim_above_thresh_recsys = SimBasedRecSys('item','cosine')\n",
        "item_item_sim_above_thresh_recsys.predict_all(rating_df_train_above_thresh, num_users, num_items)\n",
        "item_item_sim_above_thresh_recsys_testdf = item_item_sim_above_thresh_recsys.evaluate_test(rating_df_test_above_thresh)\n",
        "\n",
        "item_item_sim_below_thresh_recsys = SimBasedRecSys('item','cosine')\n",
        "item_item_sim_below_thresh_recsys.predict_all(rating_df_train_below_thresh, num_users, num_items)\n",
        "item_item_sim_below_thresh_recsys_testdf = item_item_sim_below_thresh_recsys.evaluate_test(rating_df_test_below_thresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "18021it [00:06, 2750.68it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "1979it [00:00, 2893.93it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "18021it [00:06, 2725.71it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "1979it [00:00, 2771.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizrXOH6RoxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62843d8f-48e5-4074-f1d0-2a7ce11d82da"
      },
      "source": [
        "# ((user_user_sim_above_thresh_recsys_testdf['user-cosine'] - user_user_sim_above_thresh_recsys_testdf['rating']) ** 2).mean() ** .5\n",
        "\n",
        "\n",
        "rmse_uu_above_t = CrossValidation.rmse(user_user_sim_above_thresh_recsys_testdf, 5, num_users, num_items, pred = 'user-cosine', true='rating')\n",
        "rmse_uu_below_t = CrossValidation.rmse(user_user_sim_below_thresh_recsys_testdf, 5, num_users, num_items, pred = 'user-cosine', true='rating')\n",
        "rmse_ii_above_t = CrossValidation.rmse(item_item_sim_above_thresh_recsys_testdf, 5, num_users, num_items, pred = 'item-cosine', true='rating')\n",
        "rmse_ii_below_t = CrossValidation.rmse(item_item_sim_below_thresh_recsys_testdf, 5, num_users, num_items, pred = 'item-cosine', true='rating')\n",
        "\n",
        "\n",
        "print('-------------- rmse for all cases for threshold =', threshold ,'--------------\\n')\n",
        "print('UU rmse above threshold =', rmse_uu_above_t)\n",
        "print('UU rmse below threshold =', rmse_uu_below_t)\n",
        "print('II rmse above threshold =', rmse_ii_above_t)\n",
        "print('II rmse below threshold =', rmse_ii_below_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------- rmse for all cases for threshold = 50 --------------\n",
            "\n",
            "UU rmse above threshold = 1.0201033029300688\n",
            "UU rmse below threshold = 1.1756220756956066\n",
            "II rmse above threshold = 1.0368083032128357\n",
            "II rmse below threshold = 1.2842247202258927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4D_AcGNhWN1"
      },
      "source": [
        "**---- Note ----**\n",
        "\n",
        "The threshold chosen was = 50\n",
        "\n",
        "for user user and item item, the recsys which trained on the users above the threshold frequency performed better than the recsys which trained on the users with below threshold frequency. Since the range of users were less and the data points for each user were more, hence this happened.\n",
        "\n",
        "Moreover, user user above threshold performs better than item item above threshold as users have more average count of ratings that the items have for average count of users\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjEBSNwkY8uT"
      },
      "source": [
        "## 8. Recommender system optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8_QUmdSY_Im"
      },
      "source": [
        "class CompetitionRecSys(object):\n",
        "    \"\"\"\n",
        "    You can define new methods if you need. Don't use global variables in the class. \n",
        "    \"\"\"\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=17, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "        Initialization of the class\n",
        "        1. Make sure to fill out self.pred_column_name, the name you give  to your competition method\n",
        "        \n",
        "        \"\"\"\n",
        "        ########## your code goes here ###########\n",
        "        self.pred_column_name = 'q8_comp_pred'\n",
        "        ###########         end         ###########\n",
        "\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            num_user: scalar. number of users\n",
        "            num_item: scalar. number of items\n",
        "        OUTPUT:\n",
        "            no return... \n",
        "        \n",
        "        NOTES:\n",
        "            This function is where you train your model\n",
        "        \"\"\"\n",
        "                \n",
        "        ########## your code goes here ###########\n",
        "\n",
        "        ##################################################### for user - user cosine similarity\n",
        "\n",
        "        # getting the user - item train matrix nd array UxI\n",
        "        train_matrix = dataPreprocessor(train_vec, num_user, num_item)\n",
        "\n",
        "        #getting the similarity matrix\n",
        "        uu_similarity_matrix = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
        "\n",
        "        #setting up predection matrix\n",
        "        temp_matrix = np.zeros(train_matrix.shape)  \n",
        "        temp_matrix[train_matrix.nonzero()] = 1\n",
        "        \n",
        "        #setting up multiplying factor for predictions = normalizer replacing all ones in the pred. matrix with the similarity scores\n",
        "        normalizer = np.matmul(uu_similarity_matrix, temp_matrix) #UxU (uu_simi) mul UxI(temp_matrix)\n",
        "        normalizer[normalizer == 0] = 1e-5 # help avoid errors if the normalizer is zero or there is no single similar user for a given user\n",
        "\n",
        "        # getting the predictions by similarity\n",
        "        uu_sim_predictionMatrix = np.matmul(uu_similarity_matrix, train_matrix)/normalizer\n",
        "\n",
        "        # if no one has rated this item before, use user average  \n",
        "        useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "        columns = np.sum(uu_sim_predictionMatrix, axis=0)\n",
        "        #print(columns.shape)\n",
        "        uu_sim_predictionMatrix[:, columns==0] = uu_sim_predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "\n",
        "        self.__modeluusim =  uu_sim_predictionMatrix\n",
        "\n",
        "        ##################################################### for item - item cosine similarity\n",
        "\n",
        "        #getting the similarity matrix\n",
        "\n",
        "        ii_similarity_matrix = 1 - pairwise_distances(train_matrix.T, metric='cosine')\n",
        "\n",
        "        #setting up predection matrix\n",
        "        ii_temp_matrix = np.zeros(train_matrix.T.shape)  \n",
        "        ii_temp_matrix[train_matrix.T.nonzero()] = 1\n",
        "        \n",
        "        #setting up multiplying factor for predictions = normalizer replacing all ones in the pred. matrix with the similarity scores\n",
        "        ii_normalizer = np.matmul(ii_similarity_matrix, ii_temp_matrix) #IxI (ii_simi) mul IxU(temp_matrix)\n",
        "        ii_normalizer[ii_normalizer == 0] = 1e-5 # help avoid errors if the normalizer is zero or there is no single similar user for a given user\n",
        "\n",
        "        # getting the predictions by similarity\n",
        "        ii_sim_predictionMatrix = np.matmul(ii_similarity_matrix, train_matrix.T)/ii_normalizer\n",
        "\n",
        "        # if no one has rated this item before, use user average  \n",
        "        ii_useraverage = np.sum(train_matrix.T, axis=1)/np.sum(ii_temp_matrix, axis=1)\n",
        "        # print(ii_useraverage.shape)\n",
        "        ii_columns = np.sum(ii_sim_predictionMatrix, axis=0)\n",
        "        #print(ii_columns.shape)\n",
        "        ii_sim_predictionMatrix[:, ii_columns==0] = ii_sim_predictionMatrix[:, ii_columns==0] + np.expand_dims(ii_useraverage, axis=1)\n",
        "        ii_sim_predictionMatrix = ii_sim_predictionMatrix.T\n",
        "\n",
        "        self.__modeliisim =  ii_sim_predictionMatrix\n",
        "\n",
        "        ##################################################### for PMF\n",
        "\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ###########\n",
        "    \n",
        "        self.w_Item = sqrt(0.1)*np.random.randn(num_item, self.num_feat)  # item M x D \n",
        "        self.w_User = sqrt(0.1)*np.random.randn(num_user, self.num_feat)  # user N x D \n",
        "    \n",
        "        ###########\n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########\n",
        "            \n",
        "                pred_out = np.sum(self.w_Item[batch_ItemID]*self.w_User[batch_UserID], axis=1) #size (batch_size, )\n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(self.w_Item[train_item_idx]*self.w_User[train_user_idx], axis=1) # size(pairs_train, )\n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(self.w_Item[val_item_idx]*self.w_User[val_user_idx], axis=1) #size(pairs_val, )\n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "        ###########         end         ###########    \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "\n",
        "            NOTES:\n",
        "            This function is where your model makes prediction \n",
        "            Please fill out: prediction.loc[index, self.pred_column_name] = None                            \n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            ########### your code goes here ###########\n",
        "\n",
        "            # prediction.loc[index, self.pred_column_name] = (0.5*self.__modeluusim[userID-1, itemID-1]) + (0.5*self.__modeliisim[userID-1, itemID-1]) + (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "            # prediction.loc[index, self.pred_column_name] = 0.3333*((np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]) + (0.3333*self.__modeluusim[userID-1, itemID-1]) + (0.3333*self.__modeliisim[userID-1, itemID-1])\n",
        "            prediction.loc[index, self.pred_column_name] = sum([(np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)], self.__modeluusim[userID-1, itemID-1],  self.__modeliisim[userID-1, itemID-1]])/3\n",
        "            # prediction.loc[index, self.pred_column_name] = sum([self.__modeluusim[userID-1, itemID-1],  self.__modeliisim[userID-1, itemID-1]])/2\n",
        "            \n",
        "            ###########         end         ###########\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 17)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)\n",
        "        else:\n",
        "          raise Exception(\"You need to pass in a dictionary\")\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        self.modeluusim = None\n",
        "        self.modeliisim = None\n",
        "        ##########         end         ###########\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzNDsLWUZAci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d92e9cf-0e73-436b-901a-d300526436fa"
      },
      "source": [
        "competition = CompetitionRecSys()\n",
        "competition.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 17, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':False})\n",
        "algorithm_instances = [competition]\n",
        "cv_rp = CrossValidation('RPrecision')\n",
        "rp = cv_rp.run(algorithm_instances, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm q8_comp_pred\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:11, 1673.88it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:12, 1635.97it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:11, 1688.47it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:11, 1694.83it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
            "20000it [00:11, 1696.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vedQIZN8ZAfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1139c3-9a8c-444a-b3b9-95c3b6882a8b"
      },
      "source": [
        "rp['q8_comp_pred']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.7336167289044186,\n",
              "  0.7175432024174562,\n",
              "  0.731489032728469,\n",
              "  0.7296255169031012,\n",
              "  0.7378371159304724],\n",
              " 0.7300223193767834,\n",
              " 0.7205655198112777,\n",
              " 0.7394791189422891]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clt7PoX-7FC1"
      },
      "source": [
        "**---- Breif Description ----**\n",
        "\n",
        "For the approach, an average of predictions were taken of user-cosine recsys, item-cosine recsys and PMF to get the final set of predictions. Also for PMF, l2 regularization was changed to 0.1 with epochs as 17\n",
        "\n",
        "Final mean rprec = 0.73002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G2V2BXb-zdvQ"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjWEiRzezdvR"
      },
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZ3DOSHzdvV"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4jypcIRzdvY"
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Tc_IVazdvd"
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_PmoIrWzdvf"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGA1yZ9hzdvf"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ySapEazdvg"
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyCJ1Be0zdvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a91553-1b17-4191-a8d7-9d0a4953aca1"
      },
      "source": [
        "validatePopularityRecSys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1wwQpxzdvp"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1KASm63zdvp"
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A36VedIzdvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138617b7-4852-483e-aa84-ca24b1a8f9d6"
      },
      "source": [
        "validateUserAverRecSys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlxJxooBzdvx"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvmIFAXXzdvy"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74E1PMRzdvy"
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqzEUppEzdv4"
      },
      "source": [
        "validateEuclidean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBQxFEPzdv6"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpRR_hjzdv6"
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uGIWOS7zdv8"
      },
      "source": [
        "validateCustomizedSim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMKOOB6mzdwB"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_V0gdBTzdwB"
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkausxHizdwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89095722-685d-4105-d664-4ff7c8220157"
      },
      "source": [
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IAGUMvwzdwH"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-j6pDB3zdwH"
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        item_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        item_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = item_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjAlZnpYzdwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef279c1a-bb5b-4ff6-bbeb-ee3b770634a3"
      },
      "source": [
        "validateIISimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYo97yYTCKbI"
      },
      "source": [
        "### Probabilistic Matrix Factorization Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB1_H8mxzdwO"
      },
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate PMFRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW82XMfdzdwQ"
      },
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldve7N_0DRF4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}